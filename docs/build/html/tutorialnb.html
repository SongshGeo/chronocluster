

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Introduction &mdash; ChronoCluster 0.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=938c9ccc"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Modules" href="modules.html" />
    <link rel="prev" title="Tutorial" href="tutorial.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            ChronoCluster
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="tutorial.html">Tutorial</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Spacetime-Archaeology">Spacetime Archaeology</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Key-Terms-and-Definitions">Key Terms and Definitions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Space-Time-Volume">Space-Time Volume</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example:-Representing-a-Single-Archaeological-Site-in-Space-Time">Example: Representing a Single Archaeological Site in Space-Time</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Interpreting-the-Plot">Interpreting the Plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Understanding-the-Pipe-and-PPF">Understanding the Pipe and PPF</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Explanation-of-the-Plot">Explanation of the Plot</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Representing-Spacetime-Points-in-ChronoCluster">Representing Spacetime Points in ChronoCluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#The-Point-Class">The Point Class</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Calculating-Inclusion-Probabilities">Calculating Inclusion Probabilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Custom-Probability-Classes-in-ChronoCluster">Custom Probability Classes in ChronoCluster</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Dirac-Delta:-ddelta">Dirac Delta: <code class="docutils literal notranslate"><span class="pre">ddelta</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#Radiocarbon-Date-Distribution:-calrcarbon">Radiocarbon Date Distribution: <code class="docutils literal notranslate"><span class="pre">calrcarbon</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Using-the-Point-Class-with-different-start/end-distributions">Using the Point Class with different start/end distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Multiple-Points-in-ChronoCluster">Multiple Points in ChronoCluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Example:-Generating-and-Plotting-Random-Points">Example: Generating and Plotting Random Points</a></li>
<li class="toctree-l3"><a class="reference internal" href="#id1">Explanation of the Plot</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Pairwise-Distances-and-Clustering-Statistics-in-ChronoCluster">Pairwise Distances and Clustering Statistics in ChronoCluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Temporality-and-Chronological-Uncertainty">Temporality and Chronological Uncertainty</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example:-Pairwise-Distances-with-Temporal-and-Chronological-Uncertainty">Example: Pairwise Distances with Temporal and Chronological Uncertainty</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Step-1:-Define-Time-Slices">Step 1: Define Time Slices</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Step-2:-Precompute-Inclusion-Probabilities">Step 2: Precompute Inclusion Probabilities</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Step-3:-Run-Monte-Carlo-Simulations">Step 3: Run Monte Carlo Simulations</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Step-4:-Determine-Maximum-Distance">Step 4: Determine Maximum Distance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Step-5:-Produce-Pairwise-Distances">Step 5: Produce Pairwise Distances</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Step-6:-Visualize-Clustering">Step 6: Visualize Clustering</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Interpreting-the-Clustering-Heatmap">Interpreting the Clustering Heatmap</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Statistical-Significance-and-Complete-Spatial-Randomness">Statistical Significance and Complete Spatial Randomness</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Example:-Evaluating-Statistical-Significance-Against-CSR">Example: Evaluating Statistical Significance Against CSR</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Step-1:-Create-CSR-Data">Step 1: Create CSR Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Step-2.-Calculate-Pairwise-Distance-Density-for-CSR-data">Step 2. Calculate Pairwise Distance Density for CSR data</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Step-3:-Calculate-P-Values-for-Density-Differences">Step 3: Calculate P-Values for Density Differences</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Step-4:-Plot-the-Heatmap-of-P-Values">Step 4: Plot the Heatmap of P-Values</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Explanation-of-the-Code">Explanation of the Code</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Interpretation-of-the-Heatmap">Interpretation of the Heatmap</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Other-ChronoCluster-Clustering-Statistics">Other ChronoCluster Clustering Statistics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Example-Code-for-Ripley's-K,-L,-and-G-Functions">Example Code for Ripley’s K, L, and G Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Explanation">Explanation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Baseline-Informed-Spatial-Expectation">Baseline Informed Spatial Expectation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Simulation-Example">Simulation Example</a></li>
<li class="toctree-l4"><a class="reference internal" href="#CSR-Comparison">CSR Comparison</a></li>
<li class="toctree-l4"><a class="reference internal" href="#BISE-Comparison">BISE Comparison</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Kernel-Density-Estimation-(KDE)">Kernel Density Estimation (KDE)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#KDE-Primer">KDE Primer</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Incorporating-Temporal-Information-with-kde_time">Incorporating Temporal Information with kde_time</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Context-and-Purpose">Context and Purpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="#KDE-in-Chronocluster">KDE in Chronocluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Peak-Identification">Peak Identification</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Radial-Density-and-KDE">Radial Density and KDE</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Defining-Radial-Density">Defining Radial Density</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Radial-KDE-in-chronocluster">Radial KDE in chronocluster</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">Modules</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ChronoCluster</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="tutorial.html">Tutorial</a></li>
      <li class="breadcrumb-item active">Introduction</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/tutorialnb.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Introduction">
<h1>Introduction<a class="headerlink" href="#Introduction" title="Link to this heading"></a></h1>
<p>Understanding the spatial distribution of archaeological sites and artifacts is a fundamental aspect of studying past human activities. However, a significant challenge arises when considering the temporality and chronological uncertainty associated with these points. Not all points we observe in the archaeological record were necessarily contemporaneous, and our chronometric tools for dating them often have significant uncertainties. This complicates traditional point pattern analyses, which
typically assume that all points are fixed in both space and time.</p>
<p>ChronoCluster is a Python package designed to address this challenge. It provides tools for analyzing spatial point patterns with temporality and chronological uncertainty, incorporating methods like Ripley’s K function and point-wise distance distributions to account for these factors. By allowing for the integration of temporal distributions and uncertainties into spatial analyses, ChronoCluster helps researchers obtain more accurate and meaningful insights from archaeological (and, for that
matter, historical and even palaeoclimatic) point data.</p>
<p>Key features of ChronoCluster include:</p>
<ul class="simple">
<li><p>Visualization tools for spatial point patterns, including the ability to represent temporal distributions;</p></li>
<li><p>Clustering analysis using Ripley’s K, L, and G functions, accounting for temporality (change over time) and chronological uncertainty;</p></li>
<li><p>Pairwise distance distributions accounting for both temporality and chronological uncertainty; and</p></li>
<li><p>Comparison of observed patterns to CSR (Complete Spatial Randomness) baselines to determine significant clustering or dispersion patterns.</p></li>
</ul>
<p>In this workbook, you’ll be introduced to the package, its paradigm, its terminology, and its key functions and features.</p>
</section>
<section id="Spacetime-Archaeology">
<h1>Spacetime Archaeology<a class="headerlink" href="#Spacetime-Archaeology" title="Link to this heading"></a></h1>
<p>In spatial analysis, a point represents a location of interest within a given study area. In archaeology, points often represent the locations of sites or artifacts. A point pattern is a collection of such points, which can be analyzed to reveal spatial relationships and patterns, such as clustering or dispersion.</p>
<p>Traditional point pattern analyses assume that all points are fixed in both space and time. However, in archaeology, points have temporality—each site or artifact existed at a specific time, and our ability to date these points often comes with significant uncertainties. This complicates analyses as it requires considering the temporal existence and chronological uncertainty of these points.</p>
<p>To better analyze archaeological points, we can adopt a spacetime perspective. In this framework, each point has not only spatial coordinates (x, y) but also a temporal coordinate (z), representing its existence over time. This approach allows us to visualize and analyze the temporal dimension of archaeological data, considering when each point existed and the uncertainties associated with its dating.</p>
<section id="Key-Terms-and-Definitions">
<h2>Key Terms and Definitions<a class="headerlink" href="#Key-Terms-and-Definitions" title="Link to this heading"></a></h2>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Term</p></th>
<th class="head"><p>Definition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Point</strong></p></td>
<td><p>A location of interest within a study area, represented by spatial coordinates (x, y).</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Point Pattern</strong></p></td>
<td><p>A collection of points analyzed to reveal spatial relationships and patterns.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Temporality</strong></p></td>
<td><p>The characteristic of a point having a specific existence in time.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Chronological Uncertainty</strong></p></td>
<td><p>The uncertainty associated with the dating of a point.</p></td>
</tr>
<tr class="row-even"><td><p><strong>Space-Time Volume</strong></p></td>
<td><p>A conceptual model with spatial dimensions (x, y) and a temporal dimension (z).</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Temporal Distribution</strong></p></td>
<td><p>A probability distribution representing the possible times during which a point existed.</p></td>
</tr>
<tr class="row-even"><td><p><strong>World Line</strong></p></td>
<td><p>In physics, the path that an object traces in 4-dimensional spacetime. Here, it refers to the temporal existence of a point in the space-time volume.</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Palimpsest</strong></p></td>
<td><p>An archaeological term commonly used to describe the overlap of multiple temporal layers of human activity within the same spatial location.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="Space-Time-Volume">
<h2>Space-Time Volume<a class="headerlink" href="#Space-Time-Volume" title="Link to this heading"></a></h2>
<p>A <strong>space-Time Volume</strong> (STV) refers to a conceptual model where the x and y axes represent spatial dimensions and the z axis represents the temporal dimension. Each archaeological site or artifact can be thought of as existing within this volume, with a certain temporal duration and spatial extent.</p>
</section>
<section id="Example:-Representing-a-Single-Archaeological-Site-in-Space-Time">
<h2>Example: Representing a Single Archaeological Site in Space-Time<a class="headerlink" href="#Example:-Representing-a-Single-Archaeological-Site-in-Space-Time" title="Link to this heading"></a></h2>
<p>Let’s consider an example where we have an archaeological site represented as a single point. This site has a known spatial location but uncertain temporal existence. We can model its temporal presence using probability distributions.</p>
<p>In a plot below, we’ll illustrate:</p>
<ul class="simple">
<li><p>The spatial location of the site on the x-y plane.</p></li>
<li><p>The temporal presence of the site as a vertical pipe in the space-time volume, where the z-axis represents time.</p></li>
<li><p>A <strong>time slice</strong> indicating a specific moment in time, showing the likelihood of the site’s presence during that period.</p></li>
</ul>
<p>We will need a number of libraries:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Analysis</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">chronocluster.data.simdata</span> <span class="kn">import</span> <span class="n">generate_random_points</span>
<span class="kn">from</span> <span class="nn">chronocluster</span> <span class="kn">import</span> <span class="n">clustering</span>
<span class="kn">from</span> <span class="nn">chronocluster.clustering</span> <span class="kn">import</span> <span class="n">Point</span>
<span class="kn">from</span> <span class="nn">chronocluster.data.simdata</span> <span class="kn">import</span> <span class="n">bise</span>
<span class="kn">from</span> <span class="nn">chronocluster.utils</span> <span class="kn">import</span> <span class="n">clustering_heatmap</span><span class="p">,</span> <span class="n">pdiff_heatmap</span><span class="p">,</span> <span class="n">plot_mc_points</span><span class="p">,</span> <span class="n">get_box</span><span class="p">,</span> <span class="n">chrono_plot</span>
<span class="kn">from</span> <span class="nn">chronocluster.distributions</span> <span class="kn">import</span> <span class="n">ddelta</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>

<span class="c1"># plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</pre></div>
</div>
</div>
<p>Then, we need to generate a random point using some ChronoCluster functions and probability distributions (those will be explained further down) just to illustrate some key ideas:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define cluster distributions</span>
<span class="n">cluster_center</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">cluster_std</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="c1"># randomly select point coords</span>
<span class="n">x_coord</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">cluster_center</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="n">cluster_std</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">y_coord</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">cluster_center</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">scale</span><span class="o">=</span><span class="n">cluster_std</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">start_age_mean</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">start_age_err</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">end_age_mean</span> <span class="o">=</span> <span class="mi">1200</span>
<span class="n">end_age_err</span> <span class="o">=</span> <span class="mi">50</span>

<span class="c1"># create random start and end ages with uncertainty</span>
<span class="n">start_dist</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">start_age_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">start_age_err</span><span class="p">)</span>
<span class="n">end_dist</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">end_age_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">end_age_err</span><span class="p">)</span>

<span class="c1"># finally, generate random point</span>
<span class="n">points</span> <span class="o">=</span> <span class="p">[</span><span class="n">clustering</span><span class="o">.</span><span class="n">Point</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">x_coord</span><span class="p">,</span>
              <span class="n">y</span> <span class="o">=</span> <span class="n">y_coord</span><span class="p">,</span>
              <span class="n">start_distribution</span> <span class="o">=</span> <span class="n">start_dist</span><span class="p">,</span>
              <span class="n">end_distribution</span> <span class="o">=</span> <span class="n">end_dist</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<p>And, lastly, we can call a ChronoCluster plotting function to plot the point in a spacetime volume:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Custom styling parameters</span>
<span class="n">style_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;start_mean_color&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Do not plot start mean points</span>
    <span class="s1">&#39;end_mean_color&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Do not plot end mean points</span>
    <span class="s1">&#39;mean_point_size&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;cylinder_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>  <span class="c1"># Dark grey</span>
    <span class="s1">&#39;ppf_limits&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">),</span>  <span class="c1"># Use different ppf limits</span>
    <span class="s1">&#39;shadow_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>  <span class="c1"># grey</span>
    <span class="s1">&#39;shadow_size&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;time_slice_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>  <span class="c1"># Grey</span>
    <span class="s1">&#39;time_slice_alpha&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
    <span class="s1">&#39;time_slice_point_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>  <span class="c1"># Black</span>
<span class="p">}</span>

<span class="c1"># Plot the points using the chrono_plot function with custom styling and a time slice plane</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">chrono_plot</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">style_params</span><span class="o">=</span><span class="n">style_params</span><span class="p">,</span> <span class="n">time_slice</span><span class="o">=</span><span class="mi">1100</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_box_aspect</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_6_0.png" src="_images/tutorialnb_6_0.png" />
</div>
</div>
</section>
<section id="Interpreting-the-Plot">
<h2>Interpreting the Plot<a class="headerlink" href="#Interpreting-the-Plot" title="Link to this heading"></a></h2>
<p>In this example, we generated a single point with spatial coordinates and temporal distributions for its start and end dates. The plot visualizes the point’s spatial location, its temporal presence, and its likelihood of being present at a specified time slice. This visual representation helps to introduce the concept of analyzing archaeological point patterns with both temporality and chronological uncertainty.</p>
<ul class="simple">
<li><p>Spatial Location: The x and y coordinates represent the geographical location of the archaeological site.</p></li>
<li><p>Temporal Presence: The vertical gray pipe represents the temporal presence of the site within the space-time volume. This is determined by the probability distributions for the start and end dates.</p></li>
<li><p>Time Slice: The grey, semi-transparent plane represents a specific time slice (in this case, at 1100 years). If a point’s world line intersects the plane, the intersection is represented by a black dot (time slice point) on the plane, indicating that the point is ‘present’ in the pattern at that time.</p></li>
</ul>
</section>
<section id="Understanding-the-Pipe-and-PPF">
<h2>Understanding the Pipe and PPF<a class="headerlink" href="#Understanding-the-Pipe-and-PPF" title="Link to this heading"></a></h2>
<p>The pipe illustrates the site’s temporal persistence within the space-time volume. The ends of the pipe are determined by the start and end distributions’ percent point functions (PPF). The PPF, also known as the inverse cumulative distribution function (CDF), defines the specific points in time at which the cumulative probability reaches a certain value. For instance, a PPF value at the 1st percentile (PPF(0.01)) and the 99th percentile (PPF(0.99)) gives us a range within which we are 98%
confident the event occurred.</p>
<p>To make this clearer, let’s visualize the start and end distributions of a single point and the resulting world line in a 2D plot focused only on time and not space. The horizontal axis will represent the time duration during which the point exists in the space-time volume.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the start and end distributions</span>
<span class="n">start_age_mean</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">start_age_err</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">end_age_mean</span> <span class="o">=</span> <span class="mi">1200</span>
<span class="n">end_age_err</span> <span class="o">=</span> <span class="mi">50</span>

<span class="n">start_dist</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">start_age_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">start_age_err</span><span class="p">)</span>
<span class="n">end_dist</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">end_age_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">end_age_err</span><span class="p">)</span>

<span class="c1"># Generate a range of x values (time)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span> <span class="mi">1400</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>

<span class="c1"># Plot the probability density functions (PDFs)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">start_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Start Distribution&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">end_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;End Distribution&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>

<span class="c1"># Determine the PPF limits (1st and 99th percentiles)</span>
<span class="n">start_ppf</span> <span class="o">=</span> <span class="p">(</span><span class="n">start_dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">start_dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.99</span><span class="p">))</span>
<span class="n">end_ppf</span> <span class="o">=</span> <span class="p">(</span><span class="n">end_dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">end_dist</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.99</span><span class="p">))</span>

<span class="c1"># Plot horizontal line (world line) between start and end PPFs</span>
<span class="n">world_line_y</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.002</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">world_line_y</span><span class="p">,</span> <span class="n">start_ppf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">end_ppf</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Temporal Presence (World Line)&#39;</span><span class="p">)</span>

<span class="c1"># Annotate the PPF limits</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="n">start_ppf</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[</span><span class="n">world_line_y</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">([</span><span class="n">end_ppf</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[</span><span class="n">world_line_y</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Add labels and legend</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability Density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Temporal Distributions and World Line&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.005</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">start_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">end_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()))</span>

<span class="c1"># Set y-axis limits and ticks to avoid negative values</span>
<span class="n">max_density</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">start_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">end_dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">max_density</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.000</span><span class="p">,</span> <span class="n">max_density</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">)</span> <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_8_0.png" src="_images/tutorialnb_8_0.png" />
</div>
</div>
<section id="Explanation-of-the-Plot">
<h3>Explanation of the Plot<a class="headerlink" href="#Explanation-of-the-Plot" title="Link to this heading"></a></h3>
<p>In the plot:</p>
<ul class="simple">
<li><p>The blue curve represents the start distribution, showing the probability of the site’s presence starting at different times.</p></li>
<li><p>The red curve represents the end distribution, showing the probability of the site’s presence ending at different times.</p></li>
<li><p>The gray horizontal line near the x-axis represents the world line, indicating the temporal persistence of the site within the space-time volume.</p></li>
<li><p>The blue dot marks the 1st percentiles of the start distribution.</p></li>
<li><p>The red dot marks the 99th percentiles of the end distribution.</p></li>
</ul>
<p>This plot helps visualize how the temporal distributions of a point define its temporal presence and how we can model the uncertainties associated with dating the point. The pipe in the 3D plot from before extends vertically between the PPF limits of the start and end distributions, representing the point’s presence over time.</p>
<p>The chrono_plot function makes use of these concepts to visualize the temporal persistence of points in the space-time volume. The function takes the spatial coordinates (x, y) and the temporal distributions (start and end) of points and generates a 3D plot with:</p>
<ul class="simple">
<li><p>Pipes representing the temporal presence of each point.</p></li>
<li><p>Time slice planes to visualize the presence of points at specific moments in time.</p></li>
</ul>
</section>
</section>
</section>
<section id="Representing-Spacetime-Points-in-ChronoCluster">
<h1>Representing Spacetime Points in ChronoCluster<a class="headerlink" href="#Representing-Spacetime-Points-in-ChronoCluster" title="Link to this heading"></a></h1>
<p>With these visualizations and spacetime concepts in mind, we can look at how ChronoCluster represents points in spacetime internally. The package uses a <strong>Point</strong> class. This class encapsulates both the spatial coordinates and the temporal distributions that describe when the point exists. Below, we will explain the Point class, its attributes, and key methods such as calculating inclusion probabilities for time slices.</p>
<section id="The-Point-Class">
<h2>The Point Class<a class="headerlink" href="#The-Point-Class" title="Link to this heading"></a></h2>
<p>The Point class is designed to hold information about a single point in spacetime, including its spatial location and the temporal distributions that define its presence over time.</p>
<p>Attributes:</p>
<ul class="simple">
<li><p>x (float): The x-coordinate of the point.</p></li>
<li><p>y (float): The y-coordinate of the point.</p></li>
<li><p>start_distribution (scipy.stats.rv_continuous): The probability distribution for the start date.</p></li>
<li><p>end_distribution (scipy.stats.rv_continuous): The probability distribution for the end date.</p></li>
</ul>
<p>Key Methods:</p>
<ol class="arabic simple">
<li><p>Initialization (<code class="docutils literal notranslate"><span class="pre">__init__</span></code> method):</p></li>
</ol>
<p>The constructor initializes a new Point instance with given coordinates and distributions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">start_distribution</span><span class="p">,</span> <span class="n">end_distribution</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">x</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">start_distribution</span> <span class="o">=</span> <span class="n">start_distribution</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">end_distribution</span> <span class="o">=</span> <span class="n">end_distribution</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Temporal consistency check...&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_distributions</span><span class="p">(</span><span class="n">verbose</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Checking Distributions (<code class="docutils literal notranslate"><span class="pre">_check_distributions</span></code> method):</p></li>
</ol>
<p>This private method checks the temporal consistency of the start and end distributions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_check_distributions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">verbose</span><span class="p">):</span>
    <span class="n">overlap_ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_overlap_ratio</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">overlap_ratio</span> <span class="o">&gt;</span> <span class="mf">0.25</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Significant overlap between start and end distributions. Overlap ratio: </span><span class="si">{</span><span class="n">overlap_ratio</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">start_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_distribution</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">end_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_distribution</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">end_mean</span> <span class="o">&lt;</span> <span class="n">start_mean</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: End date distribution mean (</span><span class="si">{</span><span class="n">end_mean</span><span class="si">}</span><span class="s2">) is earlier than start date distribution mean (</span><span class="si">{</span><span class="n">start_mean</span><span class="si">}</span><span class="s2">). Possible data error.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Calculating Overlap Ratio (<code class="docutils literal notranslate"><span class="pre">_calculate_overlap_ratio</span></code> method):</p></li>
</ol>
<p>This private method calculates the overlap ratio between the start and end distributions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_calculate_overlap_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">range_min</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_distribution</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_distribution</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
    <span class="n">range_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_distribution</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.99</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_distribution</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.99</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">range_min</span><span class="p">,</span> <span class="n">range_max</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">start_pdf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_distribution</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">end_pdf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_distribution</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">overlap_pdf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">start_pdf</span><span class="p">,</span> <span class="n">end_pdf</span><span class="p">)</span>
    <span class="n">overlap_area</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trapz</span><span class="p">(</span><span class="n">overlap_pdf</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">total_area_start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trapz</span><span class="p">(</span><span class="n">start_pdf</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">total_area_end</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trapz</span><span class="p">(</span><span class="n">end_pdf</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">combined_area</span> <span class="o">=</span> <span class="n">total_area_start</span> <span class="o">+</span> <span class="n">total_area_end</span>
    <span class="k">if</span> <span class="n">combined_area</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Warning: Sum of density integrals is zero! Check that start and end dates are present and, if constant, not identical.&quot;</span><span class="p">)</span>
        <span class="n">overlap_ratio</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">overlap_ratio</span> <span class="o">=</span> <span class="n">overlap_area</span> <span class="o">/</span> <span class="n">combined_area</span>
    <span class="k">return</span> <span class="n">overlap_ratio</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Calculating Inclusion Probability (<code class="docutils literal notranslate"><span class="pre">calculate_inclusion_probability</span></code> method):</p></li>
</ol>
<p>This method calculates the inclusion probability of the point for a given time slice.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_inclusion_probability</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">time_slice</span><span class="p">):</span>
    <span class="n">start_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_distribution</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">time_slice</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">start_prob</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># If start probability is zero or negative</span>
        <span class="k">return</span> <span class="mf">0.0</span>
    <span class="n">end_prob</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">end_distribution</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">time_slice</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">start_prob</span> <span class="o">*</span> <span class="n">end_prob</span>
</pre></div>
</div>
</section>
<section id="Calculating-Inclusion-Probabilities">
<h2>Calculating Inclusion Probabilities<a class="headerlink" href="#Calculating-Inclusion-Probabilities" title="Link to this heading"></a></h2>
<p>The last of these highlighted methods is a key concept in ChronoCluster. Inclusion probability – the likelihood that a point is present in the pattern at a specific time slice – is used throughout the package for analyses and plotting. The inclusion probability for a given point is calculated using the cumulative distribution function (CDF) of the start distribution and the survival function (SF) of the end distribution for that point.</p>
<ul class="simple">
<li><p>Cumulative Distribution Function (CDF): The CDF of a distribution gives the probability that a random variable is less than or equal to a certain value. For a given time slice <span class="math notranslate nohighlight">\(t\)</span>, the CDF of the start distribution <span class="math notranslate nohighlight">\(F_{start}(t)\)</span> represents the probability that the point’s existence has started by that time.</p></li>
<li><p>Survival Function (SF): The survival function, also known as the complementary cumulative distribution function, gives the probability that a random variable is greater than a certain value. For a given time slice <span class="math notranslate nohighlight">\(t\)</span>, the SF of the end distribution <span class="math notranslate nohighlight">\(S_{end}(t)\)</span> represents the probability that the point’s existence has not ended by that time.</p></li>
</ul>
<p>The inclusion probability, <span class="math notranslate nohighlight">\(P_{\text{inclusion}}\)</span>, at a time slice, <span class="math notranslate nohighlight">\(t\)</span>, is given by:</p>
<div class="math notranslate nohighlight">
\[P_{\text{inclusion}}(t) = F_{\text{start}}(t) \times S_{\text{end}}(t)\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(F_{\text{start}}(t)\)</span> is the CDF of the start distribution at time <span class="math notranslate nohighlight">\(t\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(S_{\text{end}}(t)\)</span> is the SF of the end distribution at time <span class="math notranslate nohighlight">\(t\)</span></p></li>
</ul>
</section>
<section id="Custom-Probability-Classes-in-ChronoCluster">
<h2>Custom Probability Classes in ChronoCluster<a class="headerlink" href="#Custom-Probability-Classes-in-ChronoCluster" title="Link to this heading"></a></h2>
<p>ChronoCluster allows for flexibility in representing the temporal distributions of points. A point can have different start and end distributions, which can belong to different families of probability distributions. This flexibility is essential for modeling various types of temporal uncertainties and certainties in archaeological data.</p>
<section id="Dirac-Delta:-ddelta">
<h3>Dirac Delta: <code class="docutils literal notranslate"><span class="pre">ddelta</span></code><a class="headerlink" href="#Dirac-Delta:-ddelta" title="Link to this heading"></a></h3>
<p>One of the custom probability distribution classes used in ChronoCluster is the <code class="docutils literal notranslate"><span class="pre">ddelta</span></code> class. This class represents a Dirac delta distribution, which is useful for encoding historical information where we have no uncertainty about the start or end times of a point. The ddirac class inherits from scipy.stats.rv_continuous and approximates the Dirac delta function. This distribution is characterized by a single value dd—representing a fixed time—and it is used when we are certain about the
start or end time of a point, as we might be with historical records of site founding or abandonment times, for example.</p>
<p>Here is the implementation of the ddirac class in ChronoCluster:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ddelta</span><span class="p">(</span><span class="n">rv_continuous</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Probability functions approximating the Dirac Delta&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;ddelta&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="o">=</span> <span class="n">d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">badvalue</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">d</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">xtol</span> <span class="o">=</span> <span class="mf">1e-14</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">moment_type</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shapes</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">numargs</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vecentropy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_entropy</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generic_moment</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_moment</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Probability density function&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_cdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Cumulative distribution function&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="k">def</span> <span class="nf">_sf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Survival function&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_ppf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Percent point function (inverse of cdf)&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span>

    <span class="k">def</span> <span class="nf">_rvs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Random variates&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Mean of the distribution&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">d</span>

    <span class="k">def</span> <span class="nf">var</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Variance of the distribution&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">0.0</span>

    <span class="k">def</span> <span class="nf">std</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Standard deviation of the distribution&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">0.0</span>

    <span class="k">def</span> <span class="nf">_entropy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Entropy of the distribution&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="mf">0.0</span>

    <span class="k">def</span> <span class="nf">_moment</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;nth moment of the distribution&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="o">**</span><span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</pre></div>
</div>
<section id="Explanation-of-the-ddelta-Class">
<h4>Explanation of the ddelta Class<a class="headerlink" href="#Explanation-of-the-ddelta-Class" title="Link to this heading"></a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">ddelta</span></code> class represents a distribution where all the probability mass is concentrated at a single point, <code class="docutils literal notranslate"><span class="pre">d</span></code>. This is useful for encoding certainty about the timing of an event.</p>
<ul class="simple">
<li><p>Probability Density Function (PDF): The _pdf method returns infinity at <span class="math notranslate nohighlight">\(d\)</span> and zero elsewhere, approximating the Dirac delta function.</p></li>
<li><p>Cumulative Distribution Function (CDF): The _cdf method returns 1 for any value greater than or equal to <span class="math notranslate nohighlight">\(d\)</span> and <span class="math notranslate nohighlight">\(0\)</span> otherwise.</p></li>
<li><p>Survival Function (SF): The _sf method is the complement of the CDF, returning 1 minus the CDF.</p></li>
<li><p>Percent Point Function (PPF): The _ppf method returns dd, indicating the exact point at which the probability mass is concentrated.</p></li>
<li><p>Random Variates (RVS): The _rvs method generates random variates, which are always <span class="math notranslate nohighlight">\(d\)</span>.</p></li>
<li><p>Mean and Variance: The mean method returns <span class="math notranslate nohighlight">\(d\)</span>, and the var method returns 0, indicating no variability.</p></li>
</ul>
<p>For more information on the Dirac Delta function, you can refer to the following resources:</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Dirac_delta_function">Wikipedia: Dirac Delta Function</a></p>
<p><a class="reference external" href="https://reference.wolfram.com/language/ref/DiracDelta.html">Wolfram MathWorld: Dirac Delta Function</a></p>
</section>
</section>
<section id="Radiocarbon-Date-Distribution:-calrcarbon">
<h3>Radiocarbon Date Distribution: <code class="docutils literal notranslate"><span class="pre">calrcarbon</span></code><a class="headerlink" href="#Radiocarbon-Date-Distribution:-calrcarbon" title="Link to this heading"></a></h3>
<p>Radiocarbon dating is a method used to determine the age of an object containing organic material by measuring the amount of carbon-14 <span class="math notranslate nohighlight">\(^{14}C\)</span> it contains. The decay of <span class="math notranslate nohighlight">\(^{14}C\)</span> over time follows a known half-life, which allows us to estimate the age of the sample. However, radiocarbon dates need to be calibrated because the concentration of <span class="math notranslate nohighlight">\(^{14}C\)</span> in the atmosphere has varied over time. Calibration curves, such as <a class="reference external" href="https://intcal.org">IntCal20</a>, are used to convert
radiocarbon years into calendar years.</p>
<p>The calibration process typically involves fitting the measured <span class="math notranslate nohighlight">\(^{14}C\)</span> age to a normal distribution with combined errors from both the measurement and the calibration curve. The probability density function (PDF) for a given calendar date <span class="math notranslate nohighlight">\(\tau\)</span> is calculated as follows:</p>
<div class="math notranslate nohighlight">
\[f(\tau | \mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(\mu - m(\tau))^2}{2\sigma^2} \right)\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mu\)</span> is the measured radiocarbon age.</p></li>
<li><p><span class="math notranslate nohighlight">\(m(\tau)\)</span> is the mean radiocarbon age from the calibration curve at calendar date <span class="math notranslate nohighlight">\(\tau\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\sigma\)</span> is the combined standard error, calculated as <span class="math notranslate nohighlight">\(\sqrt{\sigma_m^2 + \sigma_c^2}\)</span>, where <span class="math notranslate nohighlight">\(\sigma_m\)</span> is the measurement error and <span class="math notranslate nohighlight">\(\sigma_c\)</span> is the error from the calibration curve.</p></li>
</ul>
<p>For more information:</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Radiocarbon_dating">Wikipedia: Radiocarbon Dating</a></p>
<p><a class="reference external" href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/F622173B70F9C1597F2738DEFC597114/S0033822200033865a.pdf/bayesian_analysis_of_radiocarbon_dates.pdf">Bronk Ramsey (2009)</a></p>
<section id="Accessing-Calibration-Curves">
<h4>Accessing Calibration Curves<a class="headerlink" href="#Accessing-Calibration-Curves" title="Link to this heading"></a></h4>
<p>In ChronoCluster, we provide utility functions to access and process calibration curves. For example, the IntCal20 data can be downloaded and processed as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">download_intcal20</span><span class="p">():</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://intcal.org/curves/intcal20.14c&quot;</span>
    <span class="n">intcal20</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
    <span class="n">intcal20</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;calbp&quot;</span><span class="p">,</span> <span class="s2">&quot;c14bp&quot;</span><span class="p">,</span> <span class="s2">&quot;c14_sigma&quot;</span><span class="p">,</span> <span class="s2">&quot;f14c&quot;</span><span class="p">,</span> <span class="s2">&quot;f14c_sigma&quot;</span><span class="p">]</span>

    <span class="c1"># Create the dictionary in the required format</span>
    <span class="n">intcal20_dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;calbp&#39;</span><span class="p">:</span> <span class="n">intcal20</span><span class="p">[</span><span class="s1">&#39;calbp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
        <span class="s1">&#39;c14bp&#39;</span><span class="p">:</span> <span class="n">intcal20</span><span class="p">[</span><span class="s1">&#39;c14bp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
        <span class="s1">&#39;c14_sigma&#39;</span><span class="p">:</span> <span class="n">intcal20</span><span class="p">[</span><span class="s1">&#39;c14_sigma&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="n">intcal20_dict</span>

<span class="c1"># Example usage to create initial intcal20 dictionary</span>
<span class="n">intcal20</span> <span class="o">=</span> <span class="n">download_intcal20</span><span class="p">()</span>

<span class="c1"># Users can add their custom curves to this dictionary</span>
<span class="n">calibration_curves</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;intcal20&#39;</span><span class="p">:</span> <span class="n">intcal20</span>
<span class="p">}</span>

<span class="c1"># Users can update this dictionary with their custom curves</span>
<span class="c1"># Example: calibration_curves[&#39;custom_curve&#39;] = custom_curve_data</span>
</pre></div>
</div>
</section>
<section id="Package-Time-Convention">
<h4>Package Time Convention<a class="headerlink" href="#Package-Time-Convention" title="Link to this heading"></a></h4>
<p>For simplicity the package assumes that <strong>years BP (ybp, or bp) are negative</strong> and it would be wise for users who implement custom curves to do the same for use with ChronoCluster functions. But, this is not enforced or checked.</p>
</section>
<section id="Spline-Interpolation">
<h4>Spline Interpolation<a class="headerlink" href="#Spline-Interpolation" title="Link to this heading"></a></h4>
<p>To ensure the calibration curve is continuous and differentiable for all relevant methods, we use spline interpolation. This allows us to smoothly interpolate between the data points of the calibration curve. The interpolation is handled internally but can be affected or replaced by the user.</p>
</section>
<section id="The-calrcarbon-Class">
<h4>The <code class="docutils literal notranslate"><span class="pre">calrcarbon</span></code> Class<a class="headerlink" href="#The-calrcarbon-Class" title="Link to this heading"></a></h4>
<p>The calrcarbon class in ChronoCluster is designed to represent the calibrated radiocarbon date distribution. This class mirrors the functionality of rv_continuous in SciPy but does not inherit from it. It turned out to require too many custom method overrides to simply inherit <code class="docutils literal notranslate"><span class="pre">rv_continuous</span></code> and rely on SciPy’s internal mechanisms for generating the distribution class. Instead, the <code class="docutils literal notranslate"><span class="pre">calrcarbon</span></code> class implements custom methods to handle the PDF, CDF, survival function, and random variate
generation.</p>
<p>When an instance of the class is created, the <strong>init</strong> method automatically creates interpolation objects for the calibration curve passed/selected by class parameters and an internal method is used to get data from the interpolators:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">calrcarbon</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Custom calibrated radiocarbon date distribution&quot;&quot;&quot;</span>

    <span class="n">_interp_mean</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">_interp_error</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">calcurve</span><span class="p">,</span> <span class="n">c14_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c14_err</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="o">-</span><span class="nb">max</span><span class="p">(</span><span class="n">calcurve</span><span class="p">[</span><span class="s1">&#39;calbp&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="o">-</span><span class="nb">min</span><span class="p">(</span><span class="n">calcurve</span><span class="p">[</span><span class="s1">&#39;calbp&#39;</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">calrcarbon</span><span class="o">.</span><span class="n">_interp_mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">calrcarbon</span><span class="o">.</span><span class="n">_interp_mean</span> <span class="o">=</span> <span class="n">CubicSpline</span><span class="p">(</span><span class="o">-</span><span class="n">calcurve</span><span class="p">[</span><span class="s1">&#39;calbp&#39;</span><span class="p">],</span> <span class="o">-</span><span class="n">calcurve</span><span class="p">[</span><span class="s1">&#39;c14bp&#39;</span><span class="p">],</span> <span class="n">extrapolate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">calrcarbon</span><span class="o">.</span><span class="n">_interp_error</span> <span class="o">=</span> <span class="n">CubicSpline</span><span class="p">(</span><span class="o">-</span><span class="n">calcurve</span><span class="p">[</span><span class="s1">&#39;calbp&#39;</span><span class="p">],</span> <span class="n">calcurve</span><span class="p">[</span><span class="s1">&#39;c14_sigma&#39;</span><span class="p">],</span> <span class="n">extrapolate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c14_mean</span> <span class="o">=</span> <span class="n">c14_mean</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">c14_err</span> <span class="o">=</span> <span class="n">c14_err</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;calrcarbon&#39;</span>

    <span class="k">def</span> <span class="nf">_calc_curve_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
        <span class="n">curve_mean</span> <span class="o">=</span> <span class="n">calrcarbon</span><span class="o">.</span><span class="n">_interp_mean</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
        <span class="n">curve_error</span> <span class="o">=</span> <span class="n">calrcarbon</span><span class="o">.</span><span class="n">_interp_error</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">curve_mean</span><span class="p">,</span> <span class="n">curve_error</span>
<span class="o">...</span>
</pre></div>
</div>
<p><em>PDF: Probability Density Function</em></p>
<p>The PDF of the <code class="docutils literal notranslate"><span class="pre">calrcarbon</span></code> distribution is defined as:</p>
<div class="math notranslate nohighlight">
\[\text{pdf}(\tau | \mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(\mu - m(\tau))^2}{2\sigma^2} \right)\]</div>
<p>where <span class="math notranslate nohighlight">\(\tau\)</span> is the calendar date, <span class="math notranslate nohighlight">\(\mu\)</span> is the measured radiocarbon age, and <span class="math notranslate nohighlight">\(\sigma\)</span> is the combined error. The <code class="docutils literal notranslate"><span class="pre">_pdf</span></code> method in the <code class="docutils literal notranslate"><span class="pre">calrcarbon</span></code> class computes this value:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">c14_mean</span><span class="p">,</span> <span class="n">c14_err</span><span class="p">):</span>
    <span class="n">curve_mean</span><span class="p">,</span> <span class="n">curve_error</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calc_curve_params</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
    <span class="n">combined_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">c14_err</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">curve_error</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">c14_mean</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">curve_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">combined_error</span><span class="p">)</span>
</pre></div>
</div>
<p><em>CDF: Cumulative Distribution Function</em></p>
<p>The CDF is computed by numerically integrating the PDF. The _cdf method uses the cumulative sum of the PDF values to approximate the CDF.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_cdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">c14_mean</span><span class="p">,</span> <span class="n">c14_err</span><span class="p">):</span>
    <span class="n">t_values</span><span class="p">,</span> <span class="n">pdf_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pdf_values</span><span class="p">(</span><span class="n">c14_mean</span><span class="p">,</span> <span class="n">c14_err</span><span class="p">)</span>
    <span class="n">cdf_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pdf_values</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">t_values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">cdf_values</span> <span class="o">/=</span> <span class="n">cdf_values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">t_values</span><span class="p">,</span> <span class="n">cdf_values</span><span class="p">)</span>
</pre></div>
</div>
<p><em>SF: Survival Function</em></p>
<p>The survival function (SF) is complementary to the CDF and is calculated as <span class="math notranslate nohighlight">\(1 − CDF(τ)\)</span>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_sf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tau</span><span class="p">,</span> <span class="n">c14_mean</span><span class="p">,</span> <span class="n">c14_err</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cdf</span><span class="p">(</span><span class="n">tau</span><span class="p">,</span> <span class="n">c14_mean</span><span class="p">,</span> <span class="n">c14_err</span><span class="p">)</span>
</pre></div>
</div>
<p><em>RVS: Random Variates</em></p>
<p>Random variates are generated using the <a class="reference external" href="https://en.wikipedia.org/wiki/Inverse_transform_sampling">inverse transform sampling method</a>. The _rvs method computes the inverse of the CDF to generate samples.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_rvs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c14_mean</span><span class="p">,</span> <span class="n">c14_err</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">t_values</span><span class="p">,</span> <span class="n">pdf_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pdf_values</span><span class="p">(</span><span class="n">c14_mean</span><span class="p">,</span> <span class="n">c14_err</span><span class="p">)</span>
    <span class="n">cdf_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pdf_values</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">t_values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">cdf_values</span> <span class="o">/=</span> <span class="n">cdf_values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">uniform_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
    <span class="n">inverse_cdf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">uniform_samples</span><span class="p">,</span> <span class="n">cdf_values</span><span class="p">,</span> <span class="n">t_values</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inverse_cdf</span>
</pre></div>
</div>
<p><em>MEAN: Mean of a Calibrated Radiocarbon Date</em></p>
<p>Calibrated radiocarbon date densities tend to be skewed and multimodal. As a result, to give a sense of the location of the calibrated distribution, the <code class="docutils literal notranslate"><span class="pre">calrcarbon</span></code> class calculates an expectation from the PDF with the <code class="docutils literal notranslate"><span class="pre">mean</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c14_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">c14_err</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Public method for the mean of the distribution&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">c14_mean</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">c14_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">c14_mean</span>
        <span class="k">if</span> <span class="n">c14_err</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">c14_err</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">c14_err</span>
        <span class="n">t_values</span><span class="p">,</span> <span class="n">pdf_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_pdf_values</span><span class="p">(</span><span class="n">c14_mean</span><span class="p">,</span> <span class="n">c14_err</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">t_values</span> <span class="o">*</span> <span class="n">pdf_values</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">t_values</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">t_values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="Example-and-Plots">
<h4>Example and Plots<a class="headerlink" href="#Example-and-Plots" title="Link to this heading"></a></h4>
<p>Let’s take an example date to illustrate the calibration process and the methods implemented in the calrcarbon class. We will plot a calibrated radiocarbon date density (the PDF) using a ChronoCluster custom plotting method called <code class="docutils literal notranslate"><span class="pre">calrc_plot</span></code>, which will produce a density familiar to most who work with radicoarbon dates. And, then, we will use the <code class="docutils literal notranslate"><span class="pre">cdf</span></code> method to calculate the CDF from the PDF. For comparison, we will also sample the distribution (samples represented as a histogram in the
first plot) and call the ECDF (empirical cumulative distribution function) on that sample (this sampling is handled by a custom plotting function). Plotting both the calculated CDF and the ECDF we can determine whether the <code class="docutils literal notranslate"><span class="pre">cdf</span></code> method is working as expected.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">statsmodels.distributions.empirical_distribution</span> <span class="kn">import</span> <span class="n">ECDF</span>
<span class="kn">from</span> <span class="nn">chronocluster.calcurves</span> <span class="kn">import</span> <span class="n">calibration_curves</span>
<span class="kn">from</span> <span class="nn">chronocluster.distributions</span> <span class="kn">import</span> <span class="n">calrcarbon</span>
<span class="kn">from</span> <span class="nn">chronocluster.utils</span> <span class="kn">import</span> <span class="n">calrc_plot</span>

<span class="n">calcurve</span> <span class="o">=</span> <span class="n">calibration_curves</span><span class="p">[</span><span class="s1">&#39;intcal20&#39;</span><span class="p">]</span>

<span class="c1"># Create the custom distribution</span>
<span class="n">myc14dist</span> <span class="o">=</span> <span class="n">calrcarbon</span><span class="p">(</span><span class="n">calcurve</span><span class="p">,</span> <span class="n">c14_mean</span><span class="o">=-</span><span class="mi">5000</span><span class="p">,</span> <span class="n">c14_err</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="c1"># Plot PDF and histogram</span>
<span class="n">calrc_plot</span><span class="p">(</span><span class="n">myc14dist</span><span class="p">,</span> <span class="n">plot_type</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Plot CDF and ECDF</span>
<span class="n">calrc_plot</span><span class="p">(</span><span class="n">myc14dist</span><span class="p">,</span> <span class="n">plot_type</span><span class="o">=</span><span class="s1">&#39;cdf&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_15_0.png" src="_images/tutorialnb_15_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_15_1.png" src="_images/tutorialnb_15_1.png" />
</div>
</div>
</section>
</section>
</section>
</section>
<section id="Using-the-Point-Class-with-different-start/end-distributions">
<h1>Using the Point Class with different start/end distributions<a class="headerlink" href="#Using-the-Point-Class-with-different-start/end-distributions" title="Link to this heading"></a></h1>
<p>The ChronoCluster Point class (and relevant analyses) are intended to be flexible enough to account for points that have different start and end date/time distributions, as noted earlier. You can specify different distributions when you create a <code class="docutils literal notranslate"><span class="pre">Point</span></code> object by passing distribution objects that inherit from <code class="docutils literal notranslate"><span class="pre">scipy.stats.rv_continuous</span></code> (constinuous distribution objects). At the moment, though, Chronocluster’s data i/o functions (<code class="docutils literal notranslate"><span class="pre">chronocluster.data</span></code> module) only supports Gaussian
(<code class="docutils literal notranslate"><span class="pre">norm</span></code>), Uniform (<code class="docutils literal notranslate"><span class="pre">unif</span></code>) constant (<code class="docutils literal notranslate"><span class="pre">ddelta</span></code>) distributions. But, other functions and the <code class="docutils literal notranslate"><span class="pre">Point</span></code> class can take any valid distribution that has <code class="docutils literal notranslate"><span class="pre">.pdf</span></code>, <code class="docutils literal notranslate"><span class="pre">.cdf</span></code>, <code class="docutils literal notranslate"><span class="pre">._sf</span></code>, <code class="docutils literal notranslate"><span class="pre">.ppf</span></code>, and <code class="docutils literal notranslate"><span class="pre">.rvs</span></code> methods that return mathematically correct values.</p>
<p>In the following example, we will create a <code class="docutils literal notranslate"><span class="pre">Point</span></code> object with: - A normal distribution for the start time, representing some uncertainty. - A <code class="docutils literal notranslate"><span class="pre">ddelta</span></code> distribution for the end time, indicating that the end time is known exactly.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">point</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">Point</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
                         <span class="n">y</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
                         <span class="n">start_distribution</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">50</span><span class="p">),</span>
                         <span class="n">end_distribution</span> <span class="o">=</span> <span class="n">ddelta</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">1200</span><span class="p">))</span>

<span class="c1"># Display the point&#39;s attributes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Point Coordinates: (</span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">x</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">y</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Start Distribution: Mean = </span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">start_distribution</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">, Std = </span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">start_distribution</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End Distribution: Mean = </span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">end_distribution</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">, Std = </span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">end_distribution</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># And show the tidy in-line printing method for the Point class</span>
<span class="nb">print</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Point Coordinates: (10, 10)
Start Distribution: Mean = 1000.0, Std = 50.0
End Distribution: Mean = 1200, Std = 0.0
Point(x=10, y=10, start_distribution=norm(loc=1000.0, scale=50.0), end_distribution=ddelta(d=1200))
</pre></div></div>
</div>
<p>And in this second example, we will create a <code class="docutils literal notranslate"><span class="pre">Point</span></code> object with: - A <code class="docutils literal notranslate"><span class="pre">norm</span></code>al distribution for the start time, representing some uncertainty. - A <code class="docutils literal notranslate"><span class="pre">calrcarbon</span></code> distribution for the end time, indicating that the end time is based on a radiocarbon date. - <em>note that the ``calrcarbon`` class has no ``.std()`` method because they tend to be highly multimodal and a standard deviation would be misleading.</em></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">point</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">Point</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
                         <span class="n">y</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
                         <span class="n">start_distribution</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=-</span><span class="mi">5000</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">50</span><span class="p">),</span>
                         <span class="n">end_distribution</span> <span class="o">=</span> <span class="n">calrcarbon</span><span class="p">(</span><span class="n">calcurve</span><span class="p">,</span> <span class="n">c14_mean</span><span class="o">=-</span><span class="mi">4000</span><span class="p">,</span> <span class="n">c14_err</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>

<span class="c1"># Display the point&#39;s attributes</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Point Coordinates: (</span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">x</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">y</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Start Distribution: Mean = </span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">start_distribution</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">, Std = </span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">start_distribution</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;End Distribution: Mean = </span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">end_distribution</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">}</span><span class="s2">, Var = </span><span class="si">{</span><span class="n">point</span><span class="o">.</span><span class="n">end_distribution</span><span class="o">.</span><span class="n">variance</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># And show the tidy in-line printing method for the Point class</span>
<span class="nb">print</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Point Coordinates: (10, 10)
Start Distribution: Mean = -5000.0, Std = 50.0
End Distribution: Mean = -4471.165342918402, Var = 1043.4738324132463
Point(x=10, y=10, start_distribution=norm(loc=-5000.0, scale=50.0), end_distribution=calrcarbon(c14_mean=-4000, c14_err=20))
</pre></div></div>
</div>
</section>
<section id="Multiple-Points-in-ChronoCluster">
<h1>Multiple Points in ChronoCluster<a class="headerlink" href="#Multiple-Points-in-ChronoCluster" title="Link to this heading"></a></h1>
<p>To illustrate the capabilities of ChronoCluster in handling multiple points with varying temporal distributions, we can generate a set of random points. Each point will have its own start and end distributions, representing different durations of presence in the STV.</p>
<p>We will use the generate_random_points function to create these points. This function allows us to define cluster distributions, start and end date models, and uncertainties, and then generate a specified number of points based on these parameters. The generate_random_points Function</p>
<p>The generate_random_points function generates random points based on specified spatial and temporal distributions. Here’s a brief overview of its parameters:</p>
<ul class="simple">
<li><p>num_points (int): The number of points to generate.</p></li>
<li><p>cluster_centers (list of tuples): The centers of the clusters around which points are generated.</p></li>
<li><p>cluster_stds (list of floats): The standard deviations of the clusters.</p></li>
<li><p>start_type (str): The type of distribution for the start dates (e.g., ‘norm’ for normal distribution).</p></li>
<li><p>start_hyperparams (list): The hyperparameters for the start date distribution.</p></li>
<li><p>end_type (str): The type of distribution for the end dates (e.g., ‘constant’ for a fixed end date).</p></li>
<li><p>end_hyperparams (list): The hyperparameters for the end date distribution.</p></li>
</ul>
<p>Using this function, we can generate points that are clustered in space and have varying degrees of temporal uncertainty.</p>
<section id="Example:-Generating-and-Plotting-Random-Points">
<h2>Example: Generating and Plotting Random Points<a class="headerlink" href="#Example:-Generating-and-Plotting-Random-Points" title="Link to this heading"></a></h2>
<p>In the following example, we generate 40 random points divided into two clusters. The points have different start and end date distributions, demonstrating the flexibility of ChronoCluster.</p>
<p>Code Pipeline:</p>
<ol class="arabic simple">
<li><p>Define Cluster Distributions: We specify the centers and standard deviations for two clusters.</p></li>
<li><p>Create Start and End Age Distributions: We define different models and uncertainties for the start and end dates.</p></li>
<li><p>Generate Random Points: We use the generate_random_points function to create 40 points, with 20 points in each temporal distribution scenario.</p></li>
<li><p>Custom Styling: We define custom styling parameters for the plot.</p></li>
<li><p>Plot the Points: We use the chrono_plot function to visualize the points in the space-time volume.</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># define cluster distributions</span>
<span class="n">cluster_centers</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)]</span>
<span class="n">cluster_stds</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>

<span class="c1"># create random start and end ages with uncertainty for each point</span>
<span class="c1"># define dating models and uncertainties</span>
<span class="n">start_type</span> <span class="o">=</span> <span class="s1">&#39;norm&#39;</span>
<span class="n">start_hyperparams</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="n">end_type</span> <span class="o">=</span> <span class="s1">&#39;constant&#39;</span>
<span class="n">end_hyperparams</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1700</span><span class="p">]</span>

<span class="c1"># finally, generate 100 random points using the above models</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">generate_random_points</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span>
                                <span class="n">cluster_centers</span><span class="p">,</span>
                                <span class="n">cluster_stds</span><span class="p">,</span>
                                <span class="n">start_type</span><span class="p">,</span>
                                <span class="n">start_hyperparams</span><span class="p">,</span>
                                <span class="n">end_type</span><span class="p">,</span>
                                <span class="n">end_hyperparams</span><span class="p">)</span>

<span class="c1"># Custom styling parameters</span>
<span class="n">style_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;start_mean_color&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Do not plot start mean points</span>
    <span class="s1">&#39;end_mean_color&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Do not plot end mean points</span>
    <span class="s1">&#39;mean_point_size&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;cylinder_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>  <span class="c1"># Dark grey</span>
    <span class="s1">&#39;ppf_limits&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">),</span>  <span class="c1"># Use different ppf limits</span>
    <span class="s1">&#39;shadow_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>  <span class="c1"># grey</span>
    <span class="s1">&#39;shadow_size&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;time_slice_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>  <span class="c1"># Grey</span>
    <span class="s1">&#39;time_slice_alpha&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
    <span class="s1">&#39;time_slice_point_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>  <span class="c1"># Black</span>
<span class="p">}</span>

<span class="c1"># Plot the points using the chrono_plot function with custom styling and a time slice plane</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">chrono_plot</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">style_params</span><span class="o">=</span><span class="n">style_params</span><span class="p">,</span> <span class="n">time_slice</span><span class="o">=</span><span class="mi">1500</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_box_aspect</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_21_0.png" src="_images/tutorialnb_21_0.png" />
</div>
</div>
</section>
<section id="id1">
<h2>Explanation of the Plot<a class="headerlink" href="#id1" title="Link to this heading"></a></h2>
<p>The plot generated by the above code illustrates several key points:</p>
<ol class="arabic simple">
<li><p>Different Points Have Different Presence/Duration in the STV: Each point’s <strong>temporal presence</strong> is represented by a vertical cylinder (pipe), the <strong>world line</strong> that extends between its start and end dates. Some points have longer durations (pipes) than others.</p></li>
<li><p><strong>World Lines</strong> and <strong>Time Slice</strong> Intersections: Some points have world lines (pipes) that do not intersect the given time slice at 1500 years. These points are not present in the pattern at that specific time, which is visualized by the absence of black dots on the time slice plane at their locations.</p></li>
<li><p><strong>Palimpsest</strong> Representation: When we ignore the time dimension, we are looking at the palimpsest— the overlapping of all points in the spatial domain. This is represented in the plot by the shadows of the points on the ‘floor’ of the plot, showing the aggregated spatial distribution without considering the temporal dimension.</p></li>
</ol>
</section>
</section>
<section id="Pairwise-Distances-and-Clustering-Statistics-in-ChronoCluster">
<h1>Pairwise Distances and Clustering Statistics in ChronoCluster<a class="headerlink" href="#Pairwise-Distances-and-Clustering-Statistics-in-ChronoCluster" title="Link to this heading"></a></h1>
<p>In spatial analysis, pairwise distances are a fundamental measure used to explore clustering structures. By calculating the distances between each pair of points, we can understand how closely points are grouped together. However, temporality and chronological uncertainty complicate these calculations because points may not be contemporaneous and their exact positions in time are uncertain.</p>
<section id="Temporality-and-Chronological-Uncertainty">
<h2>Temporality and Chronological Uncertainty<a class="headerlink" href="#Temporality-and-Chronological-Uncertainty" title="Link to this heading"></a></h2>
<p>Temporality refers to the fact that each point exists in space and time, not just space. Chronological uncertainty refers to the inaccuracies in dating these points. Traditional clustering statistics do not account for these complexities, leading to potentially misleading results. Approach in ChronoCluster</p>
<p>ChronoCluster addresses these issues by:</p>
<ul class="simple">
<li><p>Propagating Uncertainty and Temporality: Using Monte Carlo (MC) simulations to propagate chronological uncertainty.</p></li>
<li><p>Applying Spacetime Thinking: Analyzing points in both spatial and temporal dimensions.</p></li>
<li><p>Using Time Slices: Breaking the analysis into discrete time slices to handle temporality.</p></li>
</ul>
<p>Key Functions:</p>
<ul class="simple">
<li><p>in_probs Function: Precomputes inclusion probabilities based on age models and time slices.</p></li>
<li><p>mc_samples Function: Runs Monte Carlo simulations to generate probable lists of points included in each time slice.</p></li>
<li><p>temporal_pairwise Function: Produces pairwise distances to explore clustering structures over time.</p></li>
<li><p>clustering_heatmap Function: Visualizes temporality and propagates chronological uncertainty into a clustering plot.</p></li>
</ul>
</section>
<section id="Example:-Pairwise-Distances-with-Temporal-and-Chronological-Uncertainty">
<h2>Example: Pairwise Distances with Temporal and Chronological Uncertainty<a class="headerlink" href="#Example:-Pairwise-Distances-with-Temporal-and-Chronological-Uncertainty" title="Link to this heading"></a></h2>
<p>The following example demonstrates how to compute and visualize pairwise distances with temporal and chronological uncertainty.</p>
<section id="Step-1:-Define-Time-Slices">
<h3>Step 1: Define Time Slices<a class="headerlink" href="#Step-1:-Define-Time-Slices" title="Link to this heading"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the time slices</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="mi">1700</span>
<span class="n">time_interval</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">time_slices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_time</span><span class="p">,</span> <span class="n">end_time</span><span class="p">,</span> <span class="n">time_interval</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
</section>
<section id="Step-2:-Precompute-Inclusion-Probabilities">
<h3>Step 2: Precompute Inclusion Probabilities<a class="headerlink" href="#Step-2:-Precompute-Inclusion-Probabilities" title="Link to this heading"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Precompute inclusion probabilities based on age models and time slices</span>
<span class="n">inclusion_probs</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">in_probs</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">time_slices</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
</section>
<section id="Step-3:-Run-Monte-Carlo-Simulations">
<h3>Step 3: Run Monte Carlo Simulations<a class="headerlink" href="#Step-3:-Run-Monte-Carlo-Simulations" title="Link to this heading"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the Monte Carlo simulation to get an ensemble of probable</span>
<span class="c1"># lists of points included in each time slice.</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">simulations</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">mc_samples</span><span class="p">(</span><span class="n">points</span><span class="p">,</span>
                                    <span class="n">time_slices</span><span class="p">,</span>
                                    <span class="n">inclusion_probs</span><span class="p">,</span>
                                    <span class="n">num_iterations</span><span class="o">=</span><span class="n">num_iterations</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
</section>
<section id="Step-4:-Determine-Maximum-Distance">
<h3>Step 4: Determine Maximum Distance<a class="headerlink" href="#Step-4:-Determine-Maximum-Distance" title="Link to this heading"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get a bounding box for use later and to extract sensible distance limits</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">get_box</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
<span class="n">max_distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<br/></pre></div>
</div>
</div>
</section>
<section id="Step-5:-Produce-Pairwise-Distances">
<h3>Step 5: Produce Pairwise Distances<a class="headerlink" href="#Step-5:-Produce-Pairwise-Distances" title="Link to this heading"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Produce pairwise distances to explore clustering structure</span>
<span class="n">pairwise_density</span><span class="p">,</span> <span class="n">support</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">temporal_pairwise</span><span class="p">(</span><span class="n">simulations</span><span class="p">,</span>
                                                         <span class="n">time_slices</span><span class="p">,</span>
                                                         <span class="n">bw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                         <span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                         <span class="n">max_distance</span><span class="o">=</span><span class="n">max_distance</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Step-6:-Visualize-Clustering">
<h3>Step 6: Visualize Clustering<a class="headerlink" href="#Step-6:-Visualize-Clustering" title="Link to this heading"></a></h3>
<p>We can visualize the clustering in a couple of ways. First with a heat map and then by randomly sleecting a time slice for plotting.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize clustering with heatmap</span>
<span class="n">clustering_heatmap</span><span class="p">(</span><span class="n">pairwise_density</span><span class="p">,</span>
                   <span class="n">support</span><span class="p">,</span>
                   <span class="n">time_slices</span><span class="p">,</span>
                   <span class="n">result_type</span><span class="o">=</span><span class="s1">&#39;Pairwise Distances&#39;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_34_0.png" src="_images/tutorialnb_34_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot to see results for a random time slice</span>
<span class="n">rnd_t</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">low</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">time_slices</span><span class="p">)))</span>

<span class="c1"># Create a line plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Plot K results</span>
<span class="n">axs</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">support</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pairwise_density</span><span class="p">[:,</span> <span class="n">rnd_t</span><span class="p">,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">axs</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Distance&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Density&#39;</span><span class="p">)</span>
<span class="n">axs</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Pairwise Distance Density for Time Slice </span><span class="si">{</span><span class="n">time_slices</span><span class="p">[</span><span class="n">rnd_t</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_35_0.png" src="_images/tutorialnb_35_0.png" />
</div>
</div>
</section>
<section id="Interpreting-the-Clustering-Heatmap">
<h3>Interpreting the Clustering Heatmap<a class="headerlink" href="#Interpreting-the-Clustering-Heatmap" title="Link to this heading"></a></h3>
<p>The heatmap generated by the <code class="docutils literal notranslate"><span class="pre">clustering_heatmap</span></code> function provides a visual representation of the temporal clustering structure of the points. Here’s an expanded explanation based on the observed heatmap:</p>
<p><strong>Axes and Color Scale</strong></p>
<ul class="simple">
<li><p>X-Axis (Time Slices): The x-axis represents discrete time slices from 1000 to 2000 years, showing the temporal dimension of the analysis.</p></li>
<li><p>Y-Axis (Distances): The y-axis represents distances between points in the spatial plane (x, y coordinates).</p></li>
<li><p>Color Scale: The color scale represents the mean pairwise distances. The color gradient from purple (low density) to yellow (high density) indicates the relative density of pairwise distances for each time slice.</p></li>
</ul>
<p><strong>Observations</strong></p>
<ol class="arabic simple">
<li><p>Persistent Clustering Over Time:</p>
<ul class="simple">
<li><p>The heatmap shows persistent clustering through time, indicated by the consistent bands of color. This means that there is a stable structure of clusters in the data across the analyzed time period.</p></li>
</ul>
</li>
<li><p>Peaks in Pairwise Distances:</p>
<ul class="simple">
<li><p>There are notable peaks in pairwise distances at around 2 and 14 spatial units. These peaks correspond to the smaller clusters and the distance between clusters, respectively.</p></li>
<li><p>The distance of 2 units represents the average distance between points within the same cluster.</p></li>
<li><p>The distance of 14 units represents the distance between points in different clusters.</p></li>
</ul>
</li>
<li><p>Chronological Uncertainty Propagation:</p>
<ul class="simple">
<li><p>The use of Monte Carlo simulations propagates the chronological uncertainty through the time slices. This is reflected in the smooth transitions and variations in color intensity over time.</p></li>
<li><p>The heatmap marginalizes the propagated chronological uncertainty, averaging the pairwise distances over multiple simulations. But it’s important to note that the map represents only one density estimate—in this case the average across MC simulations—which is marginalizing out the uncertainty and is necessary for vizualization. In reality, there is a whole distribution of these surfaces that reflects the chronological uncertainty and samples of that distribution are contained in the
<code class="docutils literal notranslate"><span class="pre">pairwise_density</span></code> array.</p></li>
</ul>
</li>
<li><p>Clusters and Time Slices:</p>
<ul class="simple">
<li><p>In general with this approach, the presence of distinct clusters could be observed across different time slices. Some clusters might not be present in all time slices due to the temporal uncertainty of the points and their temporality. In the simple example above, there is no meaningful temporality, just chronological uncertainty.</p></li>
<li><p>Points with worldlines that do not intersect a given time slice would not be present in the pattern at that specific time, which would be seen by the absence of corresponding high-density areas in the heatmap for those time slices in cases where the uncertainty was significant and/or there was also temporality in the point pattern.</p></li>
</ul>
</li>
</ol>
</section>
</section>
<section id="Statistical-Significance-and-Complete-Spatial-Randomness">
<h2>Statistical Significance and Complete Spatial Randomness<a class="headerlink" href="#Statistical-Significance-and-Complete-Spatial-Randomness" title="Link to this heading"></a></h2>
<p>In spatial analysis, evaluating the statistical significance of observed point patterns against a null hypothesis of Complete Spatial Randomness (CSR) is crucial. CSR assumes that points are distributed uniformly and independently across the study area. By comparing the observed point patterns to this null model, we can determine whether the observed clustering or dispersion is statistically significant in the sense that the patterns would be highly unlikely to occurr if the points were randomly
distributed.</p>
<p>ChronoCluster provides functions to perform this comparison and evaluate the statistical significance of point patterns with temporal and chronological uncertainty.</p>
</section>
<section id="Example:-Evaluating-Statistical-Significance-Against-CSR">
<h2>Example: Evaluating Statistical Significance Against CSR<a class="headerlink" href="#Example:-Evaluating-Statistical-Significance-Against-CSR" title="Link to this heading"></a></h2>
<p>The following example demonstrates how to calculate the p-values for density differences between observed points and a simulated CSR baseline, and then visualize these p-values using a heatmap. The basic analytical pipeline will involve generating a random point scatter that has the same temporal characteristics of the real (in our case, of course, simulated) data. To do this, ChronoCluster has a function called <code class="docutils literal notranslate"><span class="pre">csr_sample</span></code> that takes a list of <code class="docutils literal notranslate"><span class="pre">Point</span></code> instances and generates a new list
with coordinate values randomized in a way that reflects the CSR assumption. Of course, a ‘study area’ has to be defined and passed in as coordinate limits as well.</p>
<section id="Step-1:-Create-CSR-Data">
<h3>Step 1: Create CSR Data<a class="headerlink" href="#Step-1:-Create-CSR-Data" title="Link to this heading"></a></h3>
<p>We need to create a list of MC simulations as before, but this time with the CSR data. So, we follow the same procedure as above, but replace the <code class="docutils literal notranslate"><span class="pre">points</span></code> list (original data) with a csr sample.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate CSR sample</span>
<span class="n">csr_points</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">csr_sample</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">)</span>

<span class="c1"># Get CSR inclusion probabilities (remember these points have the same</span>
<span class="c1"># temporal traits as the first simulated data)</span>
<span class="n">csr_inclusion_probs</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">in_probs</span><span class="p">(</span><span class="n">csr_points</span><span class="p">,</span>
                                          <span class="n">time_slices</span><span class="p">)</span>

<span class="c1"># Get MC iterations for incorporating chronological uncertainty</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">csr_simulations</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">mc_samples</span><span class="p">(</span><span class="n">csr_points</span><span class="p">,</span>
                                        <span class="n">time_slices</span><span class="p">,</span>
                                        <span class="n">csr_inclusion_probs</span><span class="p">,</span>
                                        <span class="n">num_iterations</span> <span class="o">=</span> <span class="n">num_iterations</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Custom styling parameters</span>
<span class="n">style_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;start_mean_color&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Do not plot start mean points</span>
    <span class="s1">&#39;end_mean_color&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span> <span class="c1"># Do not plot end mean points</span>
    <span class="s1">&#39;mean_point_size&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;cylinder_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>  <span class="c1"># Dark grey</span>
    <span class="s1">&#39;ppf_limits&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">),</span>  <span class="c1"># Use different ppf limits</span>
    <span class="s1">&#39;shadow_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>  <span class="c1"># grey</span>
    <span class="s1">&#39;shadow_size&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;time_slice_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>  <span class="c1"># Grey</span>
    <span class="s1">&#39;time_slice_alpha&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
    <span class="s1">&#39;time_slice_point_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>  <span class="c1"># Black</span>
<span class="p">}</span>

<span class="c1"># Plot the points using the chrono_plot function with custom styling and a time slice plane</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">chrono_plot</span><span class="p">(</span><span class="n">csr_points</span><span class="p">,</span> <span class="n">style_params</span><span class="o">=</span><span class="n">style_params</span><span class="p">,</span> <span class="n">time_slice</span><span class="o">=</span><span class="mi">1500</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_box_aspect</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_39_0.png" src="_images/tutorialnb_39_0.png" />
</div>
</div>
</section>
<section id="Step-2.-Calculate-Pairwise-Distance-Density-for-CSR-data">
<h3>Step 2. Calculate Pairwise Distance Density for CSR data<a class="headerlink" href="#Step-2.-Calculate-Pairwise-Distance-Density-for-CSR-data" title="Link to this heading"></a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calulate the pairwise distances for the CSR sample</span>
<span class="n">csr_pairwise_density</span><span class="p">,</span> <span class="n">csr_support</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">temporal_pairwise</span><span class="p">(</span><span class="n">csr_simulations</span><span class="p">,</span>
                                                                 <span class="n">time_slices</span><span class="p">,</span>
                                                                 <span class="n">bw</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                                                                 <span class="n">density</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                                                 <span class="n">max_distance</span> <span class="o">=</span> <span class="n">max_distance</span><span class="p">)</span>

<span class="c1"># Visualize clustering with heatmap</span>
<span class="n">clustering_heatmap</span><span class="p">(</span><span class="n">csr_pairwise_density</span><span class="p">,</span>
                   <span class="n">csr_support</span><span class="p">,</span>
                   <span class="n">time_slices</span><span class="p">,</span>
                   <span class="n">result_type</span><span class="o">=</span><span class="s1">&#39;Pairwise Distances&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_41_0.png" src="_images/tutorialnb_41_0.png" />
</div>
</div>
</section>
<section id="Step-3:-Calculate-P-Values-for-Density-Differences">
<h3>Step 3: Calculate P-Values for Density Differences<a class="headerlink" href="#Step-3:-Calculate-P-Values-for-Density-Differences" title="Link to this heading"></a></h3>
<p>We use the p_diff function to calculate the p-values for density differences between the observed points and the simulated CSR baseline for each distance and time slice. Importantly, the distribution we are using for inference is for another random variable, <span class="math notranslate nohighlight">\(p_{diff} = P(observed - csr)\)</span> that reflects the chronological uncertainty in the original data. The <code class="docutils literal notranslate"><span class="pre">p_diff</span></code> function, therefore, takes in the observed statistic array (with shape <code class="docutils literal notranslate"><span class="pre">(distance,</span> <span class="pre">time,</span> <span class="pre">mc_iterations)</span></code>) and a
comparable array for the CSR simulated data and it returns p-values for the differences where the distribution refers to the <code class="docutils literal notranslate"><span class="pre">mc_simulations</span></code> axis in the arrays. So, we are considering the distirbution with respect to chronological uncertainty because samples from the start/end distributions of the points are ultimately used to produce the iterations that are reflected in that axis of the arrays.</p>
<p>The specific calculations for the p-values are as follows, where <code class="docutils literal notranslate"><span class="pre">obs</span></code> is an observed array and <code class="docutils literal notranslate"><span class="pre">csr</span></code> is the CSR baseline:</p>
<ol class="arabic">
<li><p><strong>Mean Calculation</strong>: Calculate the mean difference (<span class="math notranslate nohighlight">\(\mu_{\Delta_{ij}}\)</span>) between the observed and CSR pairwise densities across the iterations (axis=2):</p>
<div class="math notranslate nohighlight">
\[\mu_{\Delta_{ij}} = \frac{1}{N} \sum_{k=1}^{N} (\text{obs}_{ijk} - \text{csr}_{ijk})\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the number of iterations, <span class="math notranslate nohighlight">\(i\)</span> indexes the distances, <span class="math notranslate nohighlight">\(j\)</span> indexes the time slices, and <span class="math notranslate nohighlight">\(k\)</span> indexes the iterations.</p>
</li>
<li><p><strong>Standard Deviation Calculation</strong>: Calculate the standard deviation of the differences (<span class="math notranslate nohighlight">\(\sigma_{\Delta_{ij}}\)</span>) across the iterations (axis=2):</p>
<div class="math notranslate nohighlight">
\[\sigma_{\Delta_{ij}} = \sqrt{\frac{1}{N} \sum_{k=1}^{N} \left[(\text{obs}_{ijk} - \text{csr}_{ijk}) - \mu_{\Delta_{ij}}\right]^2}\]</div>
</li>
<li><p><strong>Z-score Calculation</strong>: Calculate the z-scores for each pair of distance and time slice:</p>
<div class="math notranslate nohighlight">
\[z_{\Delta_{ij}} = \frac{\mu_{\Delta_{ij}}}{\sigma_{\Delta_{ij}}}\]</div>
</li>
<li><p><strong>P-value Calculation</strong>: Calculate the p-value using the CDF of the standard normal distribution:</p>
<div class="math notranslate nohighlight">
\[\begin{split}p = \begin{cases}
1 - \Phi(z_{\Delta_{ij}}) &amp; \text{if ``greater''} \\
   \Phi(z_{\Delta_{ij}}) &amp; \text{if ``less''}
\end{cases}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Phi\)</span> is the CDF of the standard normal distribution.</p>
</li>
</ol>
<p>It’s important to emphasize that the p-values calculated in this way are <strong>not</strong> referring directly to the probability that the difference between the observed and CSR values is greater than zero. They refer to the probability of observing a value as extreme or more extreme under the null hypothesis, which in this case is the standard normal distribution (a normal distribution centred on zero and scaled). As a result, these values are comparable to a standard one-tailed z-test. That said, given
that,</p>
<ol class="arabic simple">
<li><p>the differences are calculated as <span class="math notranslate nohighlight">\(obsserved - csr\)</span>,</p></li>
<li><p>they are standardized, and</p></li>
<li><p>the CDF is used to find the p-value</p></li>
</ol>
<p>low values imply differences that are positive if <span class="math notranslate nohighlight">\(p &lt; 0.5\)</span>. This is because the null (standard normal) is centered on zero, which would have a CDF value of <span class="math notranslate nohighlight">\(0.5\)</span>. Extremely low p-values, say <span class="math notranslate nohighlight">\(p &lt; 0.05\)</span>, would indicate that the probability of observing a more extremely positive difference is low (5% or less, in case of <span class="math notranslate nohighlight">\(p &lt; 0.05\)</span>). So, while the p-values don’t directly relate to the probability that the observed difference is greater than zero, this inequality is implied
because of the way the differences are calculated and the nature of the test design as long as <span class="math notranslate nohighlight">\(p &lt; 0.5\)</span>. Higher p-values suggest a <em>negative difference</em>, which has a specific interpretation for some clustering statisitcs, like Ripley’s K.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate the p-values for density differences between the observed points and</span>
<span class="c1"># the simulated CSR baseline per distance and temporal slice</span>
<span class="n">p_diff_array</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">p_diff</span><span class="p">(</span><span class="n">pairwise_density</span><span class="p">,</span> <span class="n">csr_pairwise_density</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Step-4:-Plot-the-Heatmap-of-P-Values">
<h3>Step 4: Plot the Heatmap of P-Values<a class="headerlink" href="#Step-4:-Plot-the-Heatmap-of-P-Values" title="Link to this heading"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">pdiff_heatmap</span></code> function is used to visualize the p-values, highlighting the statistical significance of the observed clustering patterns. The interpretation depends on the underlying stastic, which at the moment can be either one of the Ripley functions (K, L, or G) or the pairwise distance density.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot the heatmap of probabilities</span>
<span class="n">pdiff_heatmap</span><span class="p">(</span><span class="n">p_diff_array</span><span class="p">,</span>
              <span class="n">time_slices</span><span class="p">,</span>
              <span class="n">csr_support</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_45_0.png" src="_images/tutorialnb_45_0.png" />
</div>
</div>
</section>
<section id="Explanation-of-the-Code">
<h3>Explanation of the Code<a class="headerlink" href="#Explanation-of-the-Code" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p>Calculate P-Values (p_diff Function): - The p_diff function compares the observed clustering statistic to the CSR baseline for that statistic. - It calculates the p-values for the difference in density for each distance and time slice, indicating the probability that the observed pattern is different from CSR in a particular direction indicated by a parameter, <code class="docutils literal notranslate"><span class="pre">condition</span></code> that defaults to ‘greater’.</p></li>
<li><p>Visualize P-Values (pdiff_heatmap Function): - The pdiff_heatmap function plots a heatmap of the p-values, with time slices on the x-axis and distances on the y-axis. - The color gradient represents the p-values, with warmer colors indicating lower (significant) p-values and cooler colors indicating higher (insignificant) p-values.</p></li>
</ol>
</section>
<section id="Interpretation-of-the-Heatmap">
<h3>Interpretation of the Heatmap<a class="headerlink" href="#Interpretation-of-the-Heatmap" title="Link to this heading"></a></h3>
<p>Since we are looking at the difference between the observed pairwise distance distribution and a comparable CSR baseline,</p>
<ol class="arabic simple">
<li><p>Low p-values: - Statistically significant clustering and/or point-distance structure at the indicated distance(s) and time(s) within the STV. - Significant here means the probability of differences as extreme or more extreme than the observed difference is low (with the probability given by the p-value). - In the heatmap, these significant regions are indicated by warmer colours.</p></li>
<li><p>High p-values: - Regions of the pairwise distance distribution (distance(s) and time(s)) that do not differ significantly from CSR within the STV. - In the heatmap, these non-significant regions are indicated by cooler colours.</p></li>
</ol>
</section>
</section>
<section id="Other-ChronoCluster-Clustering-Statistics">
<h2>Other ChronoCluster Clustering Statistics<a class="headerlink" href="#Other-ChronoCluster-Clustering-Statistics" title="Link to this heading"></a></h2>
<p>Using the same overall pipeline described above, the <code class="docutils literal notranslate"><span class="pre">ChronoCluster</span></code> package provides support for clustering analyses involving three other fundamental cluster statistics:</p>
<ol class="arabic simple">
<li><p>Ripley’s K Function: - Purpose: Measures the number of points within a given distance of each point, adjusted for the overall density of points. - Function: temporal_cluster - Parameters: calc_K=True</p></li>
<li><p>Ripley’s L Function: - Purpose: A linear transformation of Ripley’s K function that stabilizes the variance under CSR. - Function: temporal_cluster - Parameters: calc_L=True</p></li>
<li><p>Pair Correlation Function (Ripley’s G Function): - Purpose: Measures the density of points at a specific distance from a given point, providing insight into the spatial structure at different scales. - Function: temporal_cluster - Parameters: calc_G=True</p></li>
</ol>
<section id="Example-Code-for-Ripley's-K,-L,-and-G-Functions">
<h3>Example Code for Ripley’s K, L, and G Functions<a class="headerlink" href="#Example-Code-for-Ripley's-K,-L,-and-G-Functions" title="Link to this heading"></a></h3>
<p>Below is the example code for calculating Ripley’s K, L, and G functions over time using the ChronoCluster package. This code is for reference and demonstrates how to set up the calculations, but we won’t compute anything in this slide:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define distances for Ripley&#39;s K function</span>
<span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">max_distance</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>

<span class="c1"># Calculate K, L, and G functions over time</span>
<span class="n">k_results</span><span class="p">,</span> <span class="n">l_results</span><span class="p">,</span> <span class="n">g_results</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">temporal_cluster</span><span class="p">(</span><span class="n">simulations</span><span class="p">,</span>
                                                              <span class="n">distances</span><span class="p">,</span>
                                                              <span class="n">time_slices</span><span class="p">,</span>
                                                              <span class="n">calc_K</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                              <span class="n">calc_L</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                              <span class="n">calc_G</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Visualize the K function results with a heatmap</span>
<span class="n">clustering_heatmap</span><span class="p">(</span><span class="n">k_results</span><span class="p">,</span> <span class="n">distances</span><span class="p">,</span> <span class="n">time_slices</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="Explanation">
<h3>Explanation<a class="headerlink" href="#Explanation" title="Link to this heading"></a></h3>
<ol class="arabic simple">
<li><p>Define Distances: - We define a range of distances over which to calculate the clustering statistics, ensuring that the distances cover the relevant scales of spatial interaction.</p></li>
<li><p>Calculate Clustering Statistics: - The temporal_cluster function is used to calculate Ripley’s K, L, and G functions for each time slice and distance. - The parameters calc_K=True, calc_L=True, and calc_G=True indicate that all three statistics should be computed.</p></li>
<li><p>Visualize Results: - The results of the K function are visualized using a heatmap, similar to the approach taken for pairwise distances. - The clustering_heatmap function can be used to plot the results for L and G functions as well, providing insights into the clustering patterns over time and distance.</p></li>
</ol>
</section>
</section>
<section id="Baseline-Informed-Spatial-Expectation">
<h2>Baseline Informed Spatial Expectation<a class="headerlink" href="#Baseline-Informed-Spatial-Expectation" title="Link to this heading"></a></h2>
<p>Sometimes Complete Spatial Randomness (CSR) within an arbitrarily defined study area is an inadequate baseline (null). Imagine you’re analyzing the spatial distribution of archaeological sites in a landscape shaped by natural features like rivers, mountains, or coastlines. These geographic elements exert a powerful influence over where people choose to settle, so a null model that assumes spatial randomness risks missing meaningful patterns by ignoring the influence of the landscape itself. At
the same time, human activity will almost never distribute uniformly at random within an arbitrary study area owing to resource heterogeneity and the tendency at large scales for humans (and other animals) to congergate. This natural spatial bias means that patterns we observe could easily reflect baseline process constraints rather than any structured point patterns that reflect specific past cultural, eonomic, and social processes of interest. As a result, the structure imposed by landscape
and otehr baseline contraints could distort or obscure socially, culturally, or economically derived clustering. Using CSR could also potentially lead to distracting signals (effectively additional noise) in the pair-wise distance distribution (and down-stream statistics). Thus, CSR is rarely a very good null hypothesis for human activity.</p>
<p>To address this, the Baseline Informed Spatial Expectation (BISE) null model incorporates these landscape-derived constraints directly. Instead of evaluating spatial patterns against CSR, LISE can be used to simulate a spatial distribution that conforms to broad landscape influences—such as barriers, attractors, or environmental suitability gradients—while remaining agnostic about finer-grained structures (site clustering) that might still emerge. This approach allows for a baseline that is
more sensitive to the natural, lansdscape context of human settlement, helping to reveal spatial structures that are genuinely sociocultural, rather than simply a byproduct of the landscape. With BISE, researchers can better differentiate between patterns that reflect meaningful organization and those that stem from the physical environment itself.</p>
<section id="Simulation-Example">
<h3>Simulation Example<a class="headerlink" href="#Simulation-Example" title="Link to this heading"></a></h3>
<p>Let’s imagine a collection of archaeological site locations that follow a somewhat linear landscape constraint, like sites in river valley. We can simulate, as before, a pont data set using the now familiar chronocluster tools. When plotted, as you see below, the sites trend along a line. Importantly, despite there being two separate clusters of points, the tails overlap. And, thanks to the linear trend we’ve introduced here, the ‘clustering’ is more evident in the direction transverse to the
direction of the trend than it is around the two seperate means.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define cluster distributions, but with a linear trend across the landscape (e.g., river valley)</span>
<span class="n">cluster_centers</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="p">(</span><span class="mi">110</span><span class="p">,</span> <span class="mi">110</span><span class="p">),</span> <span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">120</span><span class="p">)]</span>
<span class="n">cluster_stds</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>

<span class="c1"># Define parameters for the temporal distributions</span>
<span class="n">start_age_mean</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">start_age_err</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">end_age_mean</span> <span class="o">=</span> <span class="mi">1700</span>
<span class="n">end_age_err</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Define a directional trend to simulate a river valley</span>
<span class="n">num_points_per_cluster</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">directional_slope</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Controls the degree of directional spread</span>

<span class="c1"># Generate points with clusters along a directional trend</span>
<span class="n">points</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">center</span><span class="p">,</span> <span class="n">std</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">cluster_centers</span><span class="p">,</span> <span class="n">cluster_stds</span><span class="p">):</span>
    <span class="c1"># Generate base points for this cluster</span>
    <span class="n">x_coords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">center</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">std</span><span class="p">,</span> <span class="n">num_points_per_cluster</span><span class="p">)</span>
    <span class="n">y_coords</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">center</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">std</span><span class="p">,</span> <span class="n">num_points_per_cluster</span><span class="p">)</span> <span class="c1">#+ directional_slope * x_coords</span>

    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">x_coords</span><span class="p">,</span> <span class="n">y_coords</span><span class="p">):</span>
        <span class="c1"># Create start and end distributions for each point</span>
        <span class="n">start_dist</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">start_age_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">start_age_err</span><span class="p">)</span>
        <span class="n">end_dist</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">end_age_mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">end_age_err</span><span class="p">)</span>

        <span class="c1"># Append the point with spatial and temporal distributions</span>
        <span class="n">point</span> <span class="o">=</span> <span class="n">Point</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">start_distribution</span><span class="o">=</span><span class="n">start_dist</span><span class="p">,</span> <span class="n">end_distribution</span><span class="o">=</span><span class="n">end_dist</span><span class="p">)</span>
        <span class="n">points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">point</span><span class="p">)</span>

<span class="c1"># Custom styling parameters</span>
<span class="n">style_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;start_mean_color&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Do not plot start mean points</span>
    <span class="s1">&#39;end_mean_color&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># Do not plot end mean points</span>
    <span class="s1">&#39;mean_point_size&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;cylinder_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span>  <span class="c1"># Dark grey</span>
    <span class="s1">&#39;ppf_limits&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">),</span>  <span class="c1"># Use different ppf limits</span>
    <span class="s1">&#39;shadow_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>  <span class="c1"># grey</span>
    <span class="s1">&#39;shadow_size&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;time_slice_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>  <span class="c1"># Grey</span>
    <span class="s1">&#39;time_slice_alpha&#39;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
    <span class="s1">&#39;time_slice_point_color&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>  <span class="c1"># Black</span>
<span class="p">}</span>

<span class="c1"># Plot the points using the chrono_plot function with custom styling and a time slice plane</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">chrono_plot</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">style_params</span><span class="o">=</span><span class="n">style_params</span><span class="p">,</span> <span class="n">time_slice</span><span class="o">=</span><span class="mi">1500</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_box_aspect</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mf">0.85</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_49_0.png" src="_images/tutorialnb_49_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the Monte Carlo simulation to get an ensemble of probable</span>
<span class="c1"># lists of points included in each time slice.</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">simulations</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">mc_samples</span><span class="p">(</span><span class="n">points</span><span class="p">,</span>
                                    <span class="n">time_slices</span><span class="p">,</span>
                                    <span class="n">inclusion_probs</span><span class="p">,</span>
                                    <span class="n">num_iterations</span><span class="o">=</span><span class="n">num_iterations</span><span class="p">)</span>

<span class="c1"># Get a bounding box for use later and to extract sensible distance limits</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">get_box</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
<span class="n">max_distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="c1"># set consistent pairwise bandwidth (binning of distances)</span>
<span class="n">pair_bw</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="c1"># Produce pairwise distances to explore clustering structure</span>
<span class="n">pairwise_density</span><span class="p">,</span> <span class="n">support</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">temporal_pairwise</span><span class="p">(</span><span class="n">simulations</span><span class="p">,</span>
                                                         <span class="n">time_slices</span><span class="p">,</span>
                                                         <span class="n">bw</span><span class="o">=</span><span class="n">pair_bw</span><span class="p">,</span>
                                                         <span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                                         <span class="n">max_distance</span><span class="o">=</span><span class="n">max_distance</span><span class="p">)</span>

<span class="c1"># Visualize clustering with heatmap</span>
<span class="n">clustering_heatmap</span><span class="p">(</span><span class="n">pairwise_density</span><span class="p">,</span>
                   <span class="n">support</span><span class="p">,</span>
                   <span class="n">time_slices</span><span class="p">,</span>
                   <span class="n">result_type</span><span class="o">=</span><span class="s1">&#39;Pairwise Distances&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_50_0.png" src="_images/tutorialnb_50_0.png" />
</div>
</div>
</section>
<section id="CSR-Comparison">
<h3>CSR Comparison<a class="headerlink" href="#CSR-Comparison" title="Link to this heading"></a></h3>
<p>Now, we will use CSR as the baseline (as previously in this tutorial) to identify the statistically significant modes in the pairwise distance density surface. As you can see below, the overall span of the entire set of points is emphasized in the CSR-based comparison. The disances around 28 units is twice that of the distances between the cluster centres (14 units between successive ones).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate CSR sample</span>
<span class="n">csr_points</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">csr_sample</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">)</span>

<span class="c1"># Get CSR inclusion probabilities (remember these points have the same</span>
<span class="c1"># temporal traits as the first simulated data)</span>
<span class="n">csr_inclusion_probs</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">in_probs</span><span class="p">(</span><span class="n">csr_points</span><span class="p">,</span>
                                          <span class="n">time_slices</span><span class="p">)</span>

<span class="c1"># Get MC iterations for incorporating chronological uncertainty</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">csr_simulations</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">mc_samples</span><span class="p">(</span><span class="n">csr_points</span><span class="p">,</span>
                                        <span class="n">time_slices</span><span class="p">,</span>
                                        <span class="n">csr_inclusion_probs</span><span class="p">,</span>
                                        <span class="n">num_iterations</span> <span class="o">=</span> <span class="n">num_iterations</span><span class="p">)</span>

<span class="c1"># Calulate the pairwise distances for the CSR sample</span>
<span class="n">csr_pairwise_density</span><span class="p">,</span> <span class="n">csr_support</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">temporal_pairwise</span><span class="p">(</span><span class="n">csr_simulations</span><span class="p">,</span>
                                                                 <span class="n">time_slices</span><span class="p">,</span>
                                                                 <span class="n">bw</span> <span class="o">=</span> <span class="n">pair_bw</span><span class="p">,</span>
                                                                 <span class="n">density</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                                                 <span class="n">max_distance</span> <span class="o">=</span> <span class="n">max_distance</span><span class="p">)</span>

<span class="c1"># Calculate the p-values for density differences between the observed points and</span>
<span class="c1"># the simulated CSR baseline per distance and temporal slice</span>
<span class="n">p_diff_array</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">p_diff</span><span class="p">(</span><span class="n">pairwise_density</span><span class="p">,</span> <span class="n">csr_pairwise_density</span><span class="p">)</span>

<span class="c1"># Plot the heatmap of probabilities</span>
<span class="n">pdiff_heatmap</span><span class="p">(</span><span class="n">p_diff_array</span><span class="p">,</span>
              <span class="n">time_slices</span><span class="p">,</span>
              <span class="n">csr_support</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_52_0.png" src="_images/tutorialnb_52_0.png" />
</div>
</div>
</section>
<section id="BISE-Comparison">
<h3>BISE Comparison<a class="headerlink" href="#BISE-Comparison" title="Link to this heading"></a></h3>
<p>Now, we can use the BISE as the basis for comparison. You can see in the plot below that the higher probability pairwise distance region correpsonding to the maximum distance between farthest clusters has been greatly de-emphasized. In effect, the BISE is acting like a high-pass filter, removing the effect of the overall size of the point dataset within the study area (in this case the smallest bounding box).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate LISE sample</span>
<span class="n">mean_location</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">,</span> <span class="n">simulated_coords</span><span class="p">,</span> <span class="n">bise_points</span> <span class="o">=</span> <span class="n">bise</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">nsim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">))</span>

<span class="c1"># Get LISE inclusion probabilities (similar temporal traits as the original data)</span>
<span class="n">bise_inclusion_probs</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">in_probs</span><span class="p">(</span><span class="n">bise_points</span><span class="p">,</span>
                                           <span class="n">time_slices</span><span class="p">)</span>

<span class="c1"># Get MC iterations for incorporating chronological uncertainty</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">bise_simulations</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">mc_samples</span><span class="p">(</span><span class="n">bise_points</span><span class="p">,</span>
                                         <span class="n">time_slices</span><span class="p">,</span>
                                         <span class="n">bise_inclusion_probs</span><span class="p">,</span>
                                         <span class="n">num_iterations</span><span class="o">=</span><span class="n">num_iterations</span><span class="p">)</span>

<span class="c1"># Calulate the pairwise distances for the LISE sample</span>
<span class="n">bise_pairwise_density</span><span class="p">,</span> <span class="n">bise_support</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">temporal_pairwise</span><span class="p">(</span><span class="n">bise_simulations</span><span class="p">,</span>
                                                                 <span class="n">time_slices</span><span class="p">,</span>
                                                                 <span class="n">bw</span> <span class="o">=</span> <span class="n">pair_bw</span><span class="p">,</span>
                                                                 <span class="n">density</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                                                 <span class="n">max_distance</span> <span class="o">=</span> <span class="n">max_distance</span><span class="p">)</span>

<span class="c1"># Calculate the p-values for density differences between the observed points and</span>
<span class="c1"># the simulated CSR baseline per distance and temporal slice</span>
<span class="n">p_diff_array</span> <span class="o">=</span> <span class="n">clustering</span><span class="o">.</span><span class="n">p_diff</span><span class="p">(</span><span class="n">pairwise_density</span><span class="p">,</span> <span class="n">bise_pairwise_density</span><span class="p">)</span>

<span class="c1"># Plot the heatmap of probabilities</span>
<span class="n">pdiff_heatmap</span><span class="p">(</span><span class="n">p_diff_array</span><span class="p">,</span>
              <span class="n">time_slices</span><span class="p">,</span>
              <span class="n">bise_support</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_54_0.png" src="_images/tutorialnb_54_0.png" />
</div>
</div>
</section>
</section>
<section id="Kernel-Density-Estimation-(KDE)">
<h2>Kernel Density Estimation (KDE)<a class="headerlink" href="#Kernel-Density-Estimation-(KDE)" title="Link to this heading"></a></h2>
<p>Chronocluster provides methods for Kernel Density Estimation (KDE) and for identifying specific clusters in the data. In this section, we use KDE to quantify the spatial distribution of our simulated data, providing a smooth, continuous representation of density that highlights underlying patterns at scales relevant to our analysis. KDE is a powerful, commonly-used tool for exploring how density changes across space continuousely, and it is often used for revealing subtle structure that may not
be immediately evident in raw point data alone. It is important to note, though, that KDE is an empirical approximation to the a (presumed) underlying continuous density and is, itself, not a good predictive model. It is highly sensitive to sampling error and, in general in archaeology, cannot account for temporality or chronological uncertainty. The KDE tools in the chronocluster package, however, include support for the Point object and use inclusion probabilities to weight the KDE given a set
of points with corresponding uncertain start-/end-distributions, temporality, and a time-slice from a given space-time volume.</p>
<section id="KDE-Primer">
<h3>KDE Primer<a class="headerlink" href="#KDE-Primer" title="Link to this heading"></a></h3>
<p>Kernel Density Estimation (KDE) approximates the underlying density of a spatial dataset at any arbitrary location in a specified spatial field. In a standard Gaussian KDE, the density at each location is estimated based on its distance from all observed points, weighted by a Gaussian (normal) kernel function. This produces a continuous density surface that reflects spatial intensity.</p>
<p>Mathematically, the KDE at a point x is given by:</p>
<div class="math notranslate nohighlight">
\[\hat{f}(x) = \frac{1}{n h} \sum_{i=1}^{n} K\left(\frac{x - x_i}{h}\right)\]</div>
<p>where: - $ f^​(x) $ is the estimated density at location x, - $ n $ is the total number of observed points, - $ h $ is the bandwidth parameter controlling the smoothing scale, - $ K:nbsphinx-math:<cite>left`(:nbsphinx-math:</cite>frac{x - x_i}{h}`:nbsphinx-math:<cite>right</cite>) $ is the kernel function, typically Gaussian, centered at each observed point $ x_i $​.</p>
<p>For a Gaussian kernel, K is defined as:</p>
<div class="math notranslate nohighlight">
\[K\left(\frac{x - x_i}{h}\right) = \frac{1}{\sqrt{2\pi}} \exp\left(-\frac{(x - x_i)^2}{2h^2}\right)\]</div>
<p>This formulation calculates the influence of each point $ x_i $ on the density at location $ x $, with closer points having a larger impact due to the kernel’s shape. Adjusting the bandwidth hh tunes the KDE resolution, allowing us to highlight spatial patterns and potential clusters.</p>
</section>
<section id="Incorporating-Temporal-Information-with-kde_time">
<h3>Incorporating Temporal Information with kde_time<a class="headerlink" href="#Incorporating-Temporal-Information-with-kde_time" title="Link to this heading"></a></h3>
<p>The kde_time method in the chronocluster package builds on simple KDE by integrating temporal information through probability weighting. This temporal weighting relies on the in_probs method of the Points class, which calculates each point’s probability of persistence in the space-time volume for a specified time, based on its start and end distributions. By utilizing in_probs, kde_time factors in whether each point is likely to be present within the time-slice of interest, allowing the KDE to
reflect temporal dynamics alongside spatial distribution.</p>
<p>In this method, the KDE density at a point $ x $ within a time-slice $ t $ is defined as:</p>
<div class="math notranslate nohighlight">
\[\hat{f}_{\text{time}}(x, t) = \frac{1}{n h} \sum_{i=1}^{n} P_{i}(t) \cdot K\left(\frac{x - x_i}{h}\right)\]</div>
<p>where:</p>
<ul class="simple">
<li><p>$ <span class="math">\hat{f}</span>_{<span class="math">\text{time}</span>}(x, t) $ is the density estimate at location xx for time $ t $,</p></li>
<li><p>$ P_i(t) $ is the probability that point $ x_i $​ is present at time $ t_i $, as calculated by in_probs based on the point’s start- and end-distributions.</p></li>
</ul>
<p>By referencing the in_probs function within the Points class, kde_time aligns with the chronocluster paradigm, leveraging temporal uncertainty to weight spatial density. This allows us to visualize how clusters may shift over time, capturing temporal trends in density as points appear or fade from the spatial field according to their temporal likelihood.</p>
</section>
<section id="Context-and-Purpose">
<h3>Context and Purpose<a class="headerlink" href="#Context-and-Purpose" title="Link to this heading"></a></h3>
<p>In the previous tutorial sections, we used pairwise distance distributions to examine the simulated point data for structure and clustering. Here, we can introduce a useful anlaytical concept, the ``characteristic scale(s)’’—i.e., the distance(s) at which structure emerges from the point pattern. These scales refer to the statistically significant modes in the pairwise distance densties, which capture the typical distances between points that define spatial relationships in the whole point
distribution. Through the BISE-based significance test, we identified these characteristic distances as meaningful peaks within the pairwise distance density function, indicating spatial scales at which clustering may be statistically significant (compared to an informed null expectation).</p>
<p>For KDE analysis, the choice of bandwidth is crucial because it determines the level of detail at which patterns are visualized. In practical applications, bandwidth is often selected using general “rules of thumb,” such as Silverman’s rule or Scott’s rule, which estimate bandwidth based on the overall spread of the data. However, these rules may be too generic for archaeological datasets or spatial data with distinctive, scale-dependent patterns.</p>
<p>In this analysis, we will take a more deliberate approach by basing the KDE bandwidth on the characteristic scale(s) identified earlier. This scale-informed bandwidth allows us to tailor the KDE to highlight clustering and spatial patterns specifically at the scales that were statistically validated through our pairwise distance analysis and BISE testing. By choosing a bandwidth grounded in these characteristic scales, we achieve several key benefits:</p>
<ul class="simple">
<li><p>Scientific Rigor: The bandwidth selection is not arbitrary but informed by the data’s spatial structure, leading to more reliable interpretation of clustering.</p></li>
<li><p>Scale-Specific Insight: Using characteristic scales allows us to explore density patterns at meaningful spatial resolutions, focusing on distances where significant clustering is likely, rather than smoothing over important detail.</p></li>
<li><p>Comparability: Employing a data-derived bandwidth makes it easier to compare results across similar datasets or different regions within a study, as the analysis is based on statistically meaningful patterns rather than rule-of-thumb estimates.</p></li>
</ul>
<p>This method provides a scientifically grounded approach to exploring spatial density, allowing us to interpret clustering and patterning at scales that are particularly relevant to our dataset. By integrating characteristic scales into our KDE analysis, we can create visualizations that reveal clustering patterns in a way that aligns closely with the statistical structure of the data.</p>
</section>
<section id="KDE-in-Chronocluster">
<h3>KDE in Chronocluster<a class="headerlink" href="#KDE-in-Chronocluster" title="Link to this heading"></a></h3>
<p>Chronocluster’s KDE methods offer flexible options for bandwidth selection, which controls the scale of smoothing applied to the density surface. By adjusting the bandwidth to match our characteristic scale(s), we can tune the KDE to highlight clusters at spatial scales that are most relevant to the patterns we defined with (and then recovered from) the simulated data. The KDE output will serve as the foundation for further steps, such as cluster delineation, quantifying the density at
characteristic scales, and pinpointing core areas of interest for later analyses.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">chronocluster.density</span> <span class="kn">import</span> <span class="n">kde_time</span><span class="p">,</span> <span class="n">custom_kde</span><span class="p">,</span> <span class="n">kde_peaks</span>

<span class="c1"># Define grid resolution and create the 2D grid for KDE evaluation</span>
<span class="c1"># Get a bounding box for use later and to extract sensible distance limits</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">get_box</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
<span class="n">max_distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="n">grid_resolution</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">grid_resolution</span><span class="p">)</span>
<span class="n">y_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">grid_resolution</span><span class="p">)</span>
<span class="n">x_mesh</span><span class="p">,</span> <span class="n">y_mesh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x_grid</span><span class="p">,</span> <span class="n">y_grid</span><span class="p">)</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">x_mesh</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_mesh</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set parameters for KDE, including arbitrary time_slice from simulated data</span>
<span class="n">time_slice</span> <span class="o">=</span> <span class="n">time_slices</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
<span class="n">bandwidth</span> <span class="o">=</span>  <span class="mf">1.5</span>

<span class="c1"># Calculate KDE for the chosen time slice</span>
<span class="n">kde_values</span> <span class="o">=</span> <span class="n">kde_time</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">time_slice</span><span class="p">,</span> <span class="n">bandwidth</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="n">x_mesh</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">kde_method</span><span class="o">=</span><span class="n">custom_kde</span><span class="p">)</span>

<span class="c1"># Plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">x_mesh</span><span class="p">,</span> <span class="n">y_mesh</span><span class="p">,</span> <span class="n">kde_values</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;KDE Density&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X Coordinate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y Coordinate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;KDE for Time Slice </span><span class="si">{</span><span class="n">time_slice</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_57_0.png" src="_images/tutorialnb_57_0.png" />
</div>
</div>
</section>
<section id="Peak-Identification">
<h3>Peak Identification<a class="headerlink" href="#Peak-Identification" title="Link to this heading"></a></h3>
<p>It’s clearly useful to have a rigourous and pricipled approach to identifying characteristic scales, clustering at those scales, and then to visualize the density of points with a KDE. But, it is also frequently important to identify where the clusters actually are in space.</p>
<p>The peak-finding functionality in chronocluster is designed to offer flexibility and modularity. At the core of this structure is the kde_peaks function, which acts as a high-level wrapper for several peak-finding methods. By allowing the user to select the most appropriate method and customize the peak-finding process, kde_peaks provides a unified interface for detecting peaks in KDE surfaces or point distributions.</p>
<section id="The-kde_peaks-Wrapper-Function">
<h4>The <code class="docutils literal notranslate"><span class="pre">kde_peaks</span></code> Wrapper Function<a class="headerlink" href="#The-kde_peaks-Wrapper-Function" title="Link to this heading"></a></h4>
<p>The kde_peaks function serves as a single entry point for identifying peaks across different types of data structures (e.g., KDE grids, raw point distributions) and analysis needs. It takes a range of arguments, including:</p>
<ul class="simple">
<li><p>kde_values, x_mesh, y_mesh: Used when analyzing a KDE surface grid, these parameters represent the KDE values and corresponding coordinate grids. These inputs are essential for peak-finding methods like find_peaks and peak_local_max.</p></li>
<li><p>points: A list of Point objects, each representing a point’s x and y coordinates in the dataset. This is used by the gmm_peak_finder and pymc_gmm_peak_finder methods, which operate directly on point distributions rather than KDE surfaces.</p></li>
<li><p>num_peaks: Specifies the maximum number of peaks to identify. This parameter limits the number of clusters or density peaks returned.</p></li>
<li><p>peak_finder: Allows the user to specify the desired peak-finding method. Options include:</p>
<ul>
<li><p>scipy.signal.find_peaks</p></li>
<li><p>skimage.feature.peak_local_max</p></li>
<li><p>gmm_peak_finder (Gaussian Mixture Model-based)</p></li>
<li><p>pymc_gmm_peak_finder (Bayesian GMM with temporal weighting)</p></li>
<li><p>*args and **kwargs: These allow additional parameters to be passed to the specific peak-finding function, making kde_peaks highly customizable.</p></li>
</ul>
</li>
</ul>
<p>Within the kde_peaks function, different peak-finding methods are called based on the user’s selection via peak_finder. Here’s how each method is integrated into the pipeline:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">find_peaks</span></code> (from scipy.signal) This function is used to find local maxima in a flattened KDE surface. When find_peaks is selected, kde_peaks first verifies that kde_values, x_mesh, and y_mesh are provided. The function then applies find_peaks to identify peak locations on the KDE grid, extracting the x and y coordinates of the top-ranked peaks.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">peak_local_max</span></code> (from skimage.feature) If peak_local_max is selected, kde_peaks ensures the necessary grid inputs are provided and then calls this function to find local maxima on the 2D KDE surface. The identified peaks are returned as a set of coordinates based on local density maxima.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gmm_peak_finder</span></code> (Gaussian Mixture Model) This method operates on raw point data rather than a KDE grid, so points must be provided as input. When selected, kde_peaks calls gmm_peak_finder, which applies a Gaussian Mixture Model (GMM) to fit multiple Gaussian components to the points, representing clusters as Gaussian ellipses. The peaks are sorted by their weights (i.e., the significance of each component) and returned as ranked coordinates.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pymc_gmm_peak_finder</span></code> (Bayesian Gaussian Mixture Model) This option extends the GMM approach with a Bayesian framework, integrating temporal uncertainty. Using PyMC, pymc_gmm_peak_finder fits a Bayesian GMM model to the point distribution, weighting points according to their likelihood of being present in a given time_slice. Parameters like target_scale and target_scale_sd allow further control over component size and variance. This method is particularly useful for archaeological
applications where both spatial and temporal dimensions are critical.</p></li>
</ul>
<p>Each peak-finding function in the pipeline has its own specific requirements and return structure, providing both deterministic and probabilistic options for peak detection. By wrapping these methods, kde_peaks allows users to seamlessly switch between techniques, customize parameters, and receive results in a consistent format, making Chronocluster’s peak-finding functionality both versatile and accessible.</p>
</section>
<section id="Scikit-Learn-GMM">
<h4>Scikit-Learn GMM<a class="headerlink" href="#Scikit-Learn-GMM" title="Link to this heading"></a></h4>
<p>In addition to standard and widely-used approaches to peak finding, chronocluster implements a novel one: Gaussian Mixture Models (GMM). To demonstrate the flexibility of the GMM approach, we first explore the gmm_peak_finder function. This method leverages the Scikit-Learn implementation of GMM as a peak-finding tool, a novel solution to identify clusters in spatial data distributions—even when these clusters don’t strictly follow Gaussian shapes.</p>
<p>Typically, GMM is used as a probabilistic model that a mixture of one or more Gaussian-distributions to a given dataset. However, by increasing the number of components (peaks), the GMM can serve as a highly flexible function approximation method, capable of capturing intricate functions and surfaces, including clustering structures. This flexibility allows <code class="docutils literal notranslate"><span class="pre">gmm_peak_finder</span></code> to approximate non-Gaussian clusters by combining multiple Gaussian components, each centered on a local peak.</p>
<section id="GMM-Primer">
<h5>GMM Primer<a class="headerlink" href="#GMM-Primer" title="Link to this heading"></a></h5>
<p>To really get an intuition for the GMM approach (important for the more advanced Bayesian version provided by chronocluster), we should start with a brief GMM primer. GMMs are a potentially powerful probabilistic tool for clustering data, representing complex distributions as a combination of multiple Gaussian distributions (called “components”). Each Gaussian component has parameters that define its center, spread, and importance within the overall composite distribution.</p>
<p>At its core, a GMM assumes that the data points are drawn from a mixture of several Gaussian distributions, each representing a cluster. A common example would be body mass in a sexually dimorphic population, like chimpanzees, with one sex being on average larger than the other. The total distribution of bodymasses, then, agnostic toward sex would be somewhat bimodal, and this total ‘mixed sex’ distribution could be modelled with a Gaussian mixture model that combines two normal distributions,
one for the males and one for the females.</p>
<p>Each Gaussian component in a GMM is defined by three key parameters:</p>
<ul class="simple">
<li><p>Mean ($ :nbsphinx-math:<a href="#id2"><span class="problematic" id="id3">`</span></a>mu <a href="#id4"><span class="problematic" id="id5">`</span></a>$): The center of the component, which represents the peak location in the spatial distribution.</p></li>
<li><p>Covariance ($ :nbsphinx-math:<a href="#id6"><span class="problematic" id="id7">`</span></a>Sigma <a href="#id8"><span class="problematic" id="id9">`</span></a>$): The shape and spread of the component, which defines how dispersed or elongated the cluster is around its center.</p></li>
<li><p>Weight ($ :nbsphinx-math:<a href="#id10"><span class="problematic" id="id11">`</span></a>pi <a href="#id12"><span class="problematic" id="id13">`</span></a>$): The relative importance of each component, where higher weights indicate more significant clusters within the mixture.</p></li>
</ul>
<p>Mathematically, the probability density of a point $ x $ in a GMM with $ K $ components is expressed as:</p>
<div class="math notranslate nohighlight">
\[p(x) = \sum_{k=1}^K \pi_k \cdot \mathcal{N}(x \mid \mu_k, \Sigma_k)\]</div>
<p>where:</p>
<ul class="simple">
<li><p>$ <span class="math">\pi</span><em>k $​ is the weight of the $ k</em>{th} $ component (with $ <span class="math">\sum</span>_{k=1}^K <span class="math">\pi</span>_k = 1 $),</p></li>
<li><p>$ <span class="math">\mathcal{N}`(x :nbsphinx-math:</span>mid <cite>:nbsphinx-math:</cite>mu`_k, <span class="math">\Sigma</span>_k) $ is the probability density function of the Gaussian distribution centered at $ <span class="math">\mu</span>_k $ with covariance ​$ <span class="math">\Sigma</span>_k $.</p></li>
</ul>
<p>Each data point’s likelihood is the weighted sum of probabilities under each Gaussian component, and the overall likelihood of the model is the product of these probabilities for all points. By fitting a GMM to the data, we aim to maximize this likelihood, adjusting each component’s mean, covariance, and weight to best represent the observed point distribution.</p>
</section>
</section>
<section id="Why-this-Works-for-Peak-Finding">
<h4>Why this Works for Peak Finding<a class="headerlink" href="#Why-this-Works-for-Peak-Finding" title="Link to this heading"></a></h4>
<p>GMMs are particularly suitable for peak finding in point distributions due to their probabilistic, likelihood-based nature, which makes them adaptable and statistically parsimonious:</p>
<p><strong>Likelihood Maximization and Parsimony:</strong> When fitting a GMM, we maximize the likelihood of observing the data given the parameters of each Gaussian component. The model finds the most probable arrangement of peaks (up to a specified maximum number of components) that can explain the distribution of points. This likelihood maximization inherently favors parsimonious solutions, effectively balancing model complexity with data fit. Thus, with a specified maximum number of peaks, GMM provides a
robust way to capture the dominant clustering patterns without overfitting to noise.</p>
<p><strong>Component Weights as a Measure of Peak Importance:</strong> The weight $ <span class="math">\pi</span>_k $ of each component represents the proportion of the dataset that falls under the influence of that component. This weight not only provides a measure of each peak’s prominence but also enables a principled approach to determining relative peak importance. By exploring the likelihood surface, the Gaussian Mixture Model (GMM) automatically down-weights redundant or overlapping peaks, thus effectively
reducing noise and ensuring that only the most statistically meaningful peaks receive higher weights. Importantly, the max_peaks parameter quite high in theory, as any “excess” components will naturally be assigned lower weights if they do not correspond to distinct and prominent peaks in the data. Additional tools (e.g., model selection by varying the number of peaks) could also be used to identify the best number of peaks to include.</p>
<p><strong>Flexibility to Capture Complex Cluster Shapes:</strong> By combining multiple Gaussian components, GMM can approximate non-Gaussian shapes in the data. For instance, an elongated or irregular cluster can be represented as a combination of several Gaussians, allowing GMM to adapt to a wide range of spatial patterns. This flexibility is especially useful in archaeology and spatial analysis, where clusters may not follow simple, circular distributions.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">chronocluster.density</span> <span class="kn">import</span> <span class="n">kde_peaks</span><span class="p">,</span> <span class="n">gmm_peak_finder</span>

<span class="c1"># Set up parameters for GMM peak finding using kde_peaks</span>
<span class="n">num_components</span> <span class="o">=</span> <span class="mi">8</span>  <span class="c1"># Set the maximum number of peaks/components expected</span>

<span class="c1"># Run kde_peaks with GMM as the peak-finding method</span>
<span class="c1"># Assuming coordinates is your dataset of temple locations, passed as Point objects</span>
<span class="n">peaks</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">kde_peaks</span><span class="p">(</span><span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">,</span> <span class="n">num_peaks</span><span class="o">=</span><span class="n">num_components</span><span class="p">,</span> <span class="n">peak_finder</span><span class="o">=</span><span class="n">gmm_peak_finder</span><span class="p">)</span>

<span class="c1"># Rank peaks by weight for interpretation</span>
<span class="n">ranked_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">weights</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Sort weights in descending order</span>
<span class="n">ranked_peaks</span> <span class="o">=</span> <span class="n">peaks</span><span class="p">[</span><span class="n">ranked_indices</span><span class="p">]</span>
<span class="n">ranked_weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">ranked_indices</span><span class="p">]</span>

<span class="c1"># Print or plot ranked peaks for interpretation</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Ranked Peaks (from most to least important):&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">coord</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">ranked_peaks</span><span class="p">,</span> <span class="n">ranked_weights</span><span class="p">),</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Rank </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: Peak at </span><span class="si">{</span><span class="n">coord</span><span class="si">}</span><span class="s2">, Weight = </span><span class="si">{</span><span class="n">weight</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Plot KDE with ranked peaks labeled by importance</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">x_mesh</span><span class="p">,</span> <span class="n">y_mesh</span><span class="p">,</span> <span class="n">kde_values</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">ranked_peaks</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ranked_peaks</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;GMM Peaks&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ranked_peaks</span><span class="p">[:,:]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Rank </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X Coordinate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y Coordinate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;KDE with GMM Peaks Ranked by Importance&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Ranked Peaks (from most to least important):
Rank 1: Peak at [110.04995081 109.72515766], Weight = 0.1954
Rank 2: Peak at [119.8910784  120.22295756], Weight = 0.1890
Rank 3: Peak at [99.85063395 99.54529942], Weight = 0.1476
Rank 4: Peak at [110.01985209 110.42219561], Weight = 0.1379
Rank 5: Peak at [100.48441647 100.49851671], Weight = 0.0942
Rank 6: Peak at [120.33326388 119.66382022], Weight = 0.0934
Rank 7: Peak at [ 99.5635469  100.39735664], Weight = 0.0915
Rank 8: Peak at [119.49482185 119.34126056], Weight = 0.0510
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
c:\Users\carleton\AppData\Local\miniconda3\envs\pybayes\Lib\site-packages\sklearn\cluster\_kmeans.py:1426: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.
  warnings.warn(
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_59_2.png" src="_images/tutorialnb_59_2.png" />
</div>
</div>
</section>
<section id="chronocluster-Bayesian-GMM">
<h4>chronocluster Bayesian GMM<a class="headerlink" href="#chronocluster-Bayesian-GMM" title="Link to this heading"></a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">pymc_gmm_peak_finder</span></code> method in chronocluster improves over the standard GMM approach in two key ways. First, it incorporates the characteristic scale directly as a prior for the variance of the Gaussian components, anchoring the analysis in a scale relevant to the data’s spatial structure. Second, it accounts for chronological uncertainty by weighting observations based on temporal inclusion probabilities, allowing the analysis to focus on a specified time slice while respecting
uncertainties in the temporal data.</p>
</section>
<section id="Why-Use-a-Bayesian-GMM?">
<h4>Why Use a Bayesian GMM?<a class="headerlink" href="#Why-Use-a-Bayesian-GMM?" title="Link to this heading"></a></h4>
<p>While the standard GMM provides a flexible way to identify clusters or peaks, it lacks mechanisms for handling temporal weighting and chronological uncertainty directly:</p>
<ol class="arabic simple">
<li><p><em>No Native Support for Temporality:</em> Standard GMM does not allow for weighting observations based on their likelihood of inclusion in a particular time slice. This makes it difficult to focus on temporally specific patterns without creating cumbersome workarounds, such as bootstrapping to resample data.</p></li>
<li><p><em>Handling Chronological Uncertainty:</em> In archaeological data, dates are usually uncertain, which is handled in chronocluster with probabilistic start-/end-distribution class members. By duplicating points based on their inclusion probabilities (again, calculated with a <code class="docutils literal notranslate"><span class="pre">Point</span></code> class method, <code class="docutils literal notranslate"><span class="pre">in_probs</span></code>) for a specific time slice, the Bayesian approach can naturally accommodate these uncertainties in the likelihood estimation.</p></li>
</ol>
<p>The Bayesian GMM in Chronocluster overcomes these limitations, providing a more versatile and scientifically grounded framework for analyzing spatial data with temporal dimensions.</p>
</section>
<section id="Key-Features-of-the-Bayesian-GMM-in-Chronocluster">
<h4>Key Features of the Bayesian GMM in Chronocluster<a class="headerlink" href="#Key-Features-of-the-Bayesian-GMM-in-Chronocluster" title="Link to this heading"></a></h4>
<ol class="arabic">
<li><p>Incorporation of Characteristic Scale as a Variance Prior</p>
<p>In the Bayesian GMM approach, the characteristic scale—a statistically significant distance that defines the typical spatial relationships in the data—is used to set a prior for the variance of each Gaussian component. This characteristic scale is derived from previous analyses (such as pairwise distance distributions) and provides a meaningful constraint on the spread of each cluster. By setting this prior, we guide the model to favor clusters that align with known spatial patterns,
ensuring that the estimated clusters are interpretable and relevant.</p>
<p>Mathematically, we define this prior for the variance of each Gaussian component using a Truncated Normal distribution, centered on the characteristic scale with a specified standard deviation:</p>
<div class="math notranslate nohighlight">
\[\sigma_k \sim \text{TruncatedNormal}(\mu = \xi, \sigma = \xi_\sigma, l = 0)\]</div>
<p>where</p>
<p>$ <span class="math">\xi `$ refers to the characteristic scale (statistically significant mode(s) in the pairwise distance density), $:nbsphinx-math:</span>xi`_:nbsphinx-math:<a href="#id14"><span class="problematic" id="id15">`</span></a>sigma <a href="#id16"><span class="problematic" id="id17">`</span></a>$ refers to the variability/uncertainty of that characeristic scale, and $ l $ refers to the lower bound of the distribution.</p>
<p>This prior constrains each component’s spread around the characteristic scale, encouraging the model to fit clusters that reflect real spatial patterns identified in a systematic way.</p>
</li>
<li><p>Handling of Chronological Uncertainty Through Temporal Weighting</p>
<p>The Bayesian GMM approach in Chronocluster addresses chronological uncertainty by leveraging temporal inclusion probabilities, which estimate each point’s likelihood of being present within the time slice of interest. To implement this weighting, we generate a simulated dataset in which points are duplicated in proportion to their inclusion probability, effectively weighting the likelihood calculation.</p>
<p>For example, if a point has a 0.6 probability of inclusion in the given time slice, it will appear approximately 60% more frequently in the simulated dataset than a point with a 0.1 inclusion probability. This approach lets us approximate a weighted distribution without requiring complex modifications to the GMM’s structure.</p>
<p>This duplication-based weighting allows the model to incorporate temporal uncertainty and focus on clusters that are likely to be relevant in the specified time slice, without needing to repeatedly sample or bootstrap the data, looping over the whole estimation procedure each time.</p>
<p>While this may initially appear ad-hoc, the process of duplicating points effectively reweights the likelihood in a way that is statistically coherent.</p>
<p><em>Likelihood Reweighting:</em> In a typical Bayesian GMM, the likelihood for a dataset of $ n $ points <span class="math notranslate nohighlight">\(x_i\)</span> with mixture components $ k $ is given by:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(x_i) = \prod_{i=1}^n \sum_{k=1}^K \pi_k \cdot \mathcal{N}(x_i \mid \mu_k, \Sigma_k)\]</div>
<p>where $ <span class="math">\pi</span>_k $ is again the weight for component $ k $, and $ <span class="math">\mathcal{N}`(x_i :nbsphinx-math:</span>mid <cite>:nbsphinx-math:</cite>mu`_k, <span class="math">\Sigma</span>_k) $ is the Gaussian density for component $ k $ at point $ x_i $.</p>
<p><em>Incorporating Temporal Inclusion Probabilities:</em> When we duplicate a point $ x_i $ based on its inclusion probability​ $ P_i $ (derived from <code class="docutils literal notranslate"><span class="pre">in_probs</span></code>), we effectively increase the point’s contribution to the overall likelihood by a factor proportional to ​. Each duplication increases the likelihood by:</p>
<div class="math notranslate nohighlight">
\[\prod_{j=1}^{P_i \cdot N} \sum_{k=1}^K \pi_k \cdot \mathcal{N}(x_i \mid \mu_k, \Sigma_k)\]</div>
<p>where <span class="math notranslate nohighlight">\(P_i \cdot N\)</span> is the effective number of synthetic samples for $ x_i $.</p>
<p><em>Effect on Likelihood Approximation:</em> By duplicating points in proportion to $ P_i $​, the synthetic dataset approximates the likelihood as if each observation $ x_i $ were weighted by $ P_i $​. The duplication approach effectively inflates the contribution of high-probability points and deflates low-probability points. By doing so, we avoid the complexity of formal statistical weights, and the computational overhead of bootstrapping, while maintaining statistical coherence, as the likelihood
now reflects both spatial clustering and temporal relevance.</p>
</li>
</ol>
</section>
<section id="Setting-Up-the-Bayesian-GMM-in-Chronocluster">
<h4>Setting Up the Bayesian GMM in Chronocluster<a class="headerlink" href="#Setting-Up-the-Bayesian-GMM-in-Chronocluster" title="Link to this heading"></a></h4>
<p>With these improvements, we can apply the Bayesian GMM as follows:</p>
<ol class="arabic simple">
<li><p><strong>Specify the Key Parameters</strong></p></li>
</ol>
<ul class="simple">
<li><p>Characteristic Scale: Use this as the prior mean for the Gaussian component variance, aligning each component’s spread with known spatial patterns.</p></li>
<li><p>Inclusion Probabilities: Set up a simulated dataset by duplicating points based on their inclusion probabilities for the selected time slice, providing a temporally weighted dataset. This can be done with the chronocluster function, <code class="docutils literal notranslate"><span class="pre">synth_sample</span></code>.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p><strong>Fit the Bayesian Model</strong></p></li>
</ol>
<ul class="simple">
<li><p>The Bayesian GMM uses the <code class="docutils literal notranslate"><span class="pre">pymc_gmm_peak_finder</span></code> method, which constructs a Dirichlet Process for mixture weights, defining each component’s center, variance, and weight. Given the characteristic scale as a variance prior and the temporally weighted dataset, the model iteratively adjusts parameters to maximize the posterior probability, producing clusters that reflect both spatial and temporal structures.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p><strong>Interpret the Results</strong></p></li>
</ol>
<ul class="simple">
<li><p>Peak Coordinates: The posterior mean of each component’s center indicates the coordinates of a peak, weighted by both spatial density and temporal relevance.</p></li>
<li><p>Component Weights: These weights indicate the relative prominence of each peak within the time slice, allowing us to rank and filter clusters based on significance. The <code class="docutils literal notranslate"><span class="pre">pymc_gmm_peak_finder</span></code> model incorporates a threshold parameter for identifying important components based on weights (defaults to <span class="math notranslate nohighlight">\(\frac{1}{w}\)</span>). A posterior distribution for each component, $ <span class="math">\delta</span><em>k $ is produced that reflects $ w_k - w</em>{threshold} $. This way, we can easily use credible
intervals to identify important peaks where $ P(<span class="math">\delta</span><em>k &gt; 0) &gt; 1 - :nbsphinx-math:`alpha `$ given a p-value-like threshold for $ :nbsphinx-math:`alpha `$ (e.g., 0.05) or $ HDI</em>{95}(<span class="math">\delta</span>_k) &gt; 0 $.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pymc</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">from</span> <span class="nn">chronocluster.density</span> <span class="kn">import</span> <span class="n">pymc_gmm_peak_finder</span>

<span class="c1"># Calculate the spatial extent based on bounding box to constrain the prior for</span>
<span class="c1"># the component means (parameter space outside this area is going to be fruitless)</span>
<span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">get_box</span><span class="p">(</span><span class="n">points</span><span class="p">)</span>
<span class="n">max_distance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="n">bounding_box_variance</span> <span class="o">=</span> <span class="p">(</span> <span class="n">max_distance</span><span class="o">/</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># Set maximum number of components to allow in the model</span>
<span class="n">max_components</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">w_threshold</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">max_components</span> <span class="c1"># used for idenitifying peak importance</span>

<span class="c1"># Priors for spatial scale (variance) based on pairwise distance density analysis</span>
<span class="n">target_scale</span> <span class="o">=</span> <span class="mf">1.5</span>  <span class="c1"># This is our target spatial scale for each component</span>
<span class="n">target_scale_sd</span> <span class="o">=</span> <span class="mf">0.3</span>  <span class="c1"># Some variation around this value</span>

<span class="c1"># time slice (set earlier on, but to jog the memory)</span>
<span class="n">time_slice</span> <span class="o">=</span> <span class="n">time_slices</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

<span class="c1"># Run kde_peaks with GMM as the peak-finding method</span>
<span class="c1"># Assuming coordinates is your dataset of temple locations, passed as Point objects</span>
<span class="n">peaks</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">trace</span> <span class="o">=</span> <span class="n">kde_peaks</span><span class="p">(</span><span class="n">points</span><span class="o">=</span><span class="n">points</span><span class="p">,</span>
                                    <span class="n">num_peaks</span><span class="o">=</span><span class="n">max_components</span><span class="p">,</span>
                                    <span class="n">peak_finder</span><span class="o">=</span><span class="n">pymc_gmm_peak_finder</span><span class="p">,</span>
                                    <span class="n">time_slice</span> <span class="o">=</span> <span class="n">time_slice</span><span class="p">,</span>
                                    <span class="n">target_scale</span> <span class="o">=</span> <span class="n">target_scale</span><span class="p">,</span>
                                    <span class="n">target_scale_sd</span> <span class="o">=</span> <span class="n">target_scale_sd</span><span class="p">,</span>
                                    <span class="n">w_threshold</span> <span class="o">=</span> <span class="n">w_threshold</span><span class="p">,</span>
                                    <span class="n">draws</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">,</span>
                                    <span class="n">tune</span> <span class="o">=</span> <span class="mi">6000</span><span class="p">,</span>
                                    <span class="n">chains</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sequential sampling (1 chains in 1 job)
NUTS: [w, means, chol]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "9b7f4c7d61334c8da32c82427a965418", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"></pre></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">
</pre></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sampling 1 chain for 4_000 tune and 2_000 draw iterations (4_000 + 2_000 draws total) took 761 seconds.
There were 1 divergences after tuning. Increase `target_accept` or reparameterize.
Only one chain was sampled, this makes it impossible to run some convergence checks
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">chronocluster.density</span> <span class="kn">import</span> <span class="n">rank_peaks</span>

<span class="n">importance_hdi</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">summary_df</span> <span class="o">=</span> <span class="n">rank_peaks</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">significance</span><span class="o">=</span><span class="n">importance_hdi</span><span class="p">,</span> <span class="n">source_param</span><span class="o">=</span><span class="s1">&#39;importance&#39;</span><span class="p">)</span>

<span class="c1"># isolate important peaks</span>
<span class="c1"># Filter rows where the lower bound of the HDI is greater than importance_threshold</span>
<span class="n">importance_threshold</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">condition</span> <span class="o">=</span> <span class="n">summary_df</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">importance_hdi</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="p">)</span><span class="si">}</span><span class="s1">% HDI (Importance)&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">hdi</span><span class="p">:</span> <span class="n">hdi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">importance_threshold</span><span class="p">)</span>
<span class="n">important_peaks</span> <span class="o">=</span> <span class="n">summary_df</span><span class="p">[</span><span class="n">condition</span><span class="p">]</span> <span class="c1"># isloated for plotting below</span>
<span class="n">summary_df</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Rank</th>
      <th>Importance</th>
      <th>Coordinates</th>
      <th>94% HDI (Importance)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0.105332</td>
      <td>(99.76378307410232, 99.89893518077652)</td>
      <td>(0.0554383073006188, 0.14903909300715418)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0.083037</td>
      <td>(110.0694863982973, 110.16789728029953)</td>
      <td>(-0.06717312492427938, 0.15074774085422843)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0.046629</td>
      <td>(120.26596153558248, 119.86954570912528)</td>
      <td>(-0.023997382087060842, 0.0993326944283342)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>-0.000654</td>
      <td>(100.48424406221739, 100.40982754900358)</td>
      <td>(-0.0387477139901936, 0.04816024210388181)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>-0.016397</td>
      <td>(119.64296211884407, 120.07054228884512)</td>
      <td>(-0.058344168478520364, 0.02405810082613133)</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>-0.037437</td>
      <td>(109.58644907619221, 109.83659348941625)</td>
      <td>(-0.09767962877920745, 0.11074465309619352)</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>-0.085692</td>
      <td>(110.5825390002075, 109.2740912309594)</td>
      <td>(-0.10858786954540917, -0.06433491752473684)</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>-0.094818</td>
      <td>(119.12531040662812, 119.2876128681013)</td>
      <td>(-0.11691521791045235, -0.03917915112747197)</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot KDE density surface</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">x_mesh</span><span class="p">,</span> <span class="n">y_mesh</span><span class="p">,</span> <span class="n">kde_values</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>

<span class="c1"># Extract the X and Y coordinates from the Coordinates column for plotting</span>
<span class="n">x_coords</span> <span class="o">=</span> <span class="n">important_peaks</span><span class="p">[</span><span class="s1">&#39;Coordinates&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">coord</span><span class="p">:</span> <span class="n">coord</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">y_coords</span> <span class="o">=</span> <span class="n">important_peaks</span><span class="p">[</span><span class="s1">&#39;Coordinates&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">coord</span><span class="p">:</span> <span class="n">coord</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Plot the GMM peaks with red &#39;x&#39; markers</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_coords</span><span class="p">,</span> <span class="n">y_coords</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;GMM Peaks&#39;</span><span class="p">)</span>

<span class="c1"># Annotate each component with its rank</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">x_coords</span><span class="p">,</span> <span class="n">y_coords</span><span class="p">,</span> <span class="n">important_peaks</span><span class="p">[</span><span class="s1">&#39;Rank&#39;</span><span class="p">]),</span> <span class="n">start</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="c1"># Add legend, labels, and title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X Coordinate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Y Coordinate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;KDE with GMM Peaks Ranked by Importance&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_63_0.png" src="_images/tutorialnb_63_0.png" />
</div>
</div>
</section>
<section id="MCMC-Sampling-Considerations">
<h4>MCMC Sampling Considerations<a class="headerlink" href="#MCMC-Sampling-Considerations" title="Link to this heading"></a></h4>
<p>The Bayesian GMM can be a powerful technique for identifying peaks and provides the flexibility of including both the characteristic scale and temporal uncertainty, but it comes at the cost of having to deal with Markov-Chain Monte Carlo (MCMC) tools, diagnostics, and computational challenges.</p>
<p>One important consideration is <em>convergnce</em>. Convergence refers to the point at which the MCMC chain(s) have thoroughly explored the parameter space and stabilized around a posterior distribution. In other words, when the sampling process has reached a stationary distribution that accurately reflects the underlying posterior, we can be confident in the results. A typical Bayesian analysis nowadays frequently involves using multiple chains to improve and diagnosis convergence (multiple MCMC
simulations with different starting parameters that ideally lead to the same conclusions, but explore the potential parameter space(s) more thoroughly and quickly). In PyMC, it’s possible to set a parameter, <code class="docutils literal notranslate"><span class="pre">chains</span></code>, to use multiple chains and automatically run some convergence checks and then combine the chains for efficient posterior inference. This parameter can be passed through to the PyMC model from <code class="docutils literal notranslate"><span class="pre">kde_peaks</span></code> with by including it in the function call as a named parameter—it gets
passed through with <code class="docutils literal notranslate"><span class="pre">**kwargs</span></code> to PyMCs <code class="docutils literal notranslate"><span class="pre">sample</span></code> method inside the model context.</p>
<p>But, with a GMM, there’s a phenomenon called ‘label switching’ that can lead to poor convergence and multimodal posteriors if we use multiple chains. This occurs because the components in a mixture model aren’t inherently ordered. Each chain, in principle, can assign different labels to the same underlying cluster (in one run, the model calls a given cluster ‘component[0]’ and in another run the same cluster is by chance called ‘component[1]’, even though the labels refer to the same underlying
object), resulting in posterior distributions that appear multimodal when they’re actually capturing the same clusters with inconsistent labels across chains.</p>
<p>So, instead, I recommend using a single chain for a longer time (pass the <code class="docutils literal notranslate"><span class="pre">**kwargs</span></code> <code class="docutils literal notranslate"><span class="pre">draws</span> <span class="pre">=</span> <span class="pre">N</span></code> where <code class="docutils literal notranslate"><span class="pre">N</span></code> is some large integer and <code class="docutils literal notranslate"><span class="pre">chains</span> <span class="pre">=</span> <span class="pre">1</span></code> in the <code class="docutils literal notranslate"><span class="pre">kde_peaks</span></code> function call). By doing this, you avoid the complications of label-switching, as there’s no need for the MCMC sampler to align labels across chains. Of course, this approach isn’t without trade-offs. Running multiple chains allows for certain convergence diagnostics, like the Gelman-Rubin statistic, which measures
consistency across chains. With a single chain, you lose that particular diagnostic. Instead, you’ll need to rely on tools like the Geweke diagnostic, which compares different segments of a single chain to check for convergence, or just inspect the trace plots to verify that the chain has stabilized.</p>
<p>Another downside to a single-chain approach is the inability to parallelize. When you’re working with large datasets, the ability to run multiple chains simultaneously can speed up sampling considerably. With one chain, you’re limited to sequential sampling, which may lead to longer runtimes depending on the complexity of the data and model.</p>
<p>For most practical purposes, though, sticking with one chain is the cleaner approach. If you do need to use multiple chains and find that label switching has occurred, there are ad hoc methods to try aligning the clusters afterwards. However, these are often complicated and prone to introducing their own issues. Generally, running a single, longer chain will be better, even if it means giving up some parallelization and diagnostic options.</p>
<p>Some standard PyMC related methods for plotting and checking posterior chains and densities are as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>

<span class="c1"># Plot trace and posterior density for each parameter</span>
<span class="c1"># Make sure `trace` is an InferenceData object returned from pm.sample</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="s1">&#39;means&#39;</span><span class="p">,</span><span class="s1">&#39;chol&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot posterior density</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="s1">&#39;means&#39;</span><span class="p">,</span> <span class="s1">&#39;chol&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_65_0.png" src="_images/tutorialnb_65_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_65_1.png" src="_images/tutorialnb_65_1.png" />
</div>
</div>
<p>And, then, to summarize the posteriors:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Summary to see mean cluster coordinate values and credible intervals, for example</span>
<span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;means&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
arviz - WARNING - Shape validation failed: input_shape: (1, 2000), minimum_shape: (chains=2, draws=4)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>means[0, 0]</th>
      <td>110.583</td>
      <td>0.110</td>
      <td>110.386</td>
      <td>110.773</td>
      <td>0.028</td>
      <td>0.020</td>
      <td>17.0</td>
      <td>278.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[0, 1]</th>
      <td>109.274</td>
      <td>0.168</td>
      <td>108.955</td>
      <td>109.573</td>
      <td>0.009</td>
      <td>0.007</td>
      <td>326.0</td>
      <td>427.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[1, 0]</th>
      <td>100.484</td>
      <td>0.053</td>
      <td>100.386</td>
      <td>100.577</td>
      <td>0.005</td>
      <td>0.004</td>
      <td>98.0</td>
      <td>810.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[1, 1]</th>
      <td>100.410</td>
      <td>0.149</td>
      <td>100.134</td>
      <td>100.618</td>
      <td>0.055</td>
      <td>0.041</td>
      <td>8.0</td>
      <td>88.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[2, 0]</th>
      <td>109.586</td>
      <td>0.186</td>
      <td>109.322</td>
      <td>109.969</td>
      <td>0.024</td>
      <td>0.017</td>
      <td>75.0</td>
      <td>35.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[2, 1]</th>
      <td>109.837</td>
      <td>0.141</td>
      <td>109.622</td>
      <td>110.056</td>
      <td>0.024</td>
      <td>0.017</td>
      <td>48.0</td>
      <td>29.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[3, 0]</th>
      <td>119.125</td>
      <td>0.144</td>
      <td>118.876</td>
      <td>119.385</td>
      <td>0.016</td>
      <td>0.011</td>
      <td>91.0</td>
      <td>206.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[3, 1]</th>
      <td>119.288</td>
      <td>0.303</td>
      <td>118.900</td>
      <td>119.971</td>
      <td>0.081</td>
      <td>0.059</td>
      <td>22.0</td>
      <td>69.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[4, 0]</th>
      <td>119.643</td>
      <td>0.142</td>
      <td>119.461</td>
      <td>119.984</td>
      <td>0.023</td>
      <td>0.017</td>
      <td>71.0</td>
      <td>62.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[4, 1]</th>
      <td>120.071</td>
      <td>0.079</td>
      <td>119.935</td>
      <td>120.216</td>
      <td>0.004</td>
      <td>0.003</td>
      <td>642.0</td>
      <td>628.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[5, 0]</th>
      <td>120.266</td>
      <td>0.076</td>
      <td>120.155</td>
      <td>120.437</td>
      <td>0.018</td>
      <td>0.013</td>
      <td>27.0</td>
      <td>80.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[5, 1]</th>
      <td>119.870</td>
      <td>0.073</td>
      <td>119.706</td>
      <td>119.988</td>
      <td>0.020</td>
      <td>0.015</td>
      <td>14.0</td>
      <td>108.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[6, 0]</th>
      <td>99.764</td>
      <td>0.062</td>
      <td>99.637</td>
      <td>99.851</td>
      <td>0.022</td>
      <td>0.016</td>
      <td>10.0</td>
      <td>176.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[6, 1]</th>
      <td>99.899</td>
      <td>0.060</td>
      <td>99.802</td>
      <td>100.024</td>
      <td>0.015</td>
      <td>0.011</td>
      <td>20.0</td>
      <td>41.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[7, 0]</th>
      <td>110.069</td>
      <td>0.104</td>
      <td>109.964</td>
      <td>110.232</td>
      <td>0.024</td>
      <td>0.018</td>
      <td>12.0</td>
      <td>30.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>means[7, 1]</th>
      <td>110.168</td>
      <td>0.157</td>
      <td>110.014</td>
      <td>110.669</td>
      <td>0.039</td>
      <td>0.028</td>
      <td>11.0</td>
      <td>33.0</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
</section>
</section>
<section id="Radial-Density-and-KDE">
<h2>Radial Density and KDE<a class="headerlink" href="#Radial-Density-and-KDE" title="Link to this heading"></a></h2>
<p>Once important peaks have been identified, there is more we can do with them. Imagine a situation where we are investigating archaeological settlement patterns and where a prominent feature—such as a settlement or natural resource—forms a focal point. In such contexts, it can be informative to characterize how point density changes with increasing distance from this central feature. Geographers, especially Urban Geographers, describe these patterns with radial density profiles, which offer a
way to measure and visualize how density decreases or increases radially outward from a given point. For example, in a cityscape, we might expect a central peak of density representing the urban core, with density gradually decreasing as we move outward.</p>
<section id="Defining-Radial-Density">
<h3>Defining Radial Density<a class="headerlink" href="#Defining-Radial-Density" title="Link to this heading"></a></h3>
<p>Radial density profiles estimate the density of points within circular bands (or “rings”) at increasing distances from a central point. Imagine a series of concentric rings around a peak—each ring represents a distance from the center, and within each ring, we measure how many points exist per unit area. This approach captures how density is organized around a focal point, allowing for comparisons across distances that could reveal patterns like clustering, uniform spread, or gradients.</p>
<section id="Estimating-Radial-Density-Using-Radial-Bins">
<h4>Estimating Radial Density Using Radial Bins<a class="headerlink" href="#Estimating-Radial-Density-Using-Radial-Bins" title="Link to this heading"></a></h4>
<p>The traditional approach to estimating radial density involves dividing the area around the peak into a series of radial bins, each defined by a specific distance from the central point. For each bin, we calculate the density as the number of points within the bin divided by its area, giving a sense of how dense the region is at that distance. This total density within the ring is actually also the average density, which is a much more helpful way to interpret the resulting profile that tracks
changes in this metric with increasing distance (radii) from the central point.</p>
<p>For intuition-building, consider a simple case: dividing each radial bin into smaller, equally-sized segments (like slicing each ring into thin pie slices). If we calculate the density within each segment, then average these segment densities, we approach the overall density of the full ring. It’s easy to see this when we consider that densities are simple ratios and we are holding the magnitude of the denominator (the size of the slices) constant.</p>
<p>Consider a radial bin at some distance $ r $ from a center point, with an outer radius $ r:nbsphinx-math:<a href="#id18"><span class="problematic" id="id19">`</span></a>Delta <a href="#id20"><span class="problematic" id="id21">`</span></a>r $. The area $ A $ of this ring (bin) is:</p>
<div class="math notranslate nohighlight">
\[A = \pi(r + \Delta r)^2 - r^2 = \pi\Delta r \cdot (2r + \Delta r)\]</div>
<p>Now, imagine that we divide this radial bin into $ n $ equally-sized segments, like thin pie slices, where each <span class="math notranslate nohighlight">\(i^{th}\)</span> segment has an area <span class="math notranslate nohighlight">\(A_i\)</span> and contains <span class="math notranslate nohighlight">\(p_i\)</span> points. The density $ d_i $ within each segment is simply:</p>
<div class="math notranslate nohighlight">
\[d_i = \frac{p_i}{A_i}\]</div>
<p>If we sum the points in all segments and then average their densities, $ <span class="math">\hat{A}</span> $ , we get:</p>
<div class="math notranslate nohighlight">
\[\hat{A} = \frac{a}{n} \sum_{i=1}^n d_i = \frac{a}{n} \sum_{i=1}^n \frac{p_i}{A_i}\]</div>
<p>Since each segment’s area $ A_i $ is the same by construction, we can factor it out and rewrite this expression as:</p>
<div class="math notranslate nohighlight">
\[\hat{A} \approx A = \frac{\sum_{i=1}^n p_i}{\sum_{i=1}^n A_i} = \frac{\text{Total Points}}{\text{Total Area}}\]</div>
<p>This is just the total density within the entire radial bin.</p>
<p>As $ n <span class="math">\to `:nbsphinx-math:</span>infty <a href="#id22"><span class="problematic" id="id23">`</span></a>$, the segments become infinitely thin, and this average density converges to the density calculated over the entire ring area. This shows that the radial density within a bin is effectively an aggregate of densities around the ring at that distance. In other words, when we calculate radial density by averaging over smaller segments, we are capturing the density around the ring in a way that approaches the total density for that radius as our
segments get infinitely thin. IT also demonstrates that we can interpret the total density within a radial bin as the average density around the ring.</p>
</section>
<section id="Introducing-Radial-KDE-as-a-Continuous-Extension">
<h4>Introducing Radial KDE as a Continuous Extension<a class="headerlink" href="#Introducing-Radial-KDE-as-a-Continuous-Extension" title="Link to this heading"></a></h4>
<p>The binning approach described above is effective but inherently discrete, as it relies on fixed-width radial bins. A natural extension to this method is Radial KDE (Kernel Density Estimation), which allows us to estimate density smoothly and continuously at any given radius from the peak. Radial KDE takes the continuous KDE surface, integrates it along a ring at the specified radius, and produces a density estimate. This approach smooths out local variations that might emerge from binning,
giving a clearer view of the general density trend across distances. Importantly, it’s conceptually similar to the bin-segment averaging explained above in that the resulting single value per ring ammounts to an average (continuous) density estimate and this average gets better (more accurate) the higher our sampling density on the ring is.</p>
<p>Slightly more formally, for Radial KDE, we start by defining a sequence of concentric rings at increasing radii, <span class="math notranslate nohighlight">\(\{ r_1, r_2, … , r_n ​\}\)</span>​, from a central point (typically one of the identified peaks from before). For each radius $ r_i $​, we sample the continuous KDE surface along the circumference of the ring defined by $ r_i $ to obtain an average density at that distance.</p>
<ol class="arabic">
<li><p>Defining the Ring: At a given radius $ r $ from the central point, the circumference of the ring is $ C(r) = 2:nbsphinx-math:<a href="#id24"><span class="problematic" id="id25">`</span></a>pi <a href="#id26"><span class="problematic" id="id27">`</span></a>r $.</p></li>
<li><p>Sampling the KDE Surface: Sample points along the circumference of the ring at $ k $ equal angular intervals, say $ { <span class="math">\theta</span>_1, <span class="math">\theta</span>_2, …, <span class="math">\theta</span>_k } $ ​, where $ <span class="math">\theta</span>_j = <span class="math">\frac{2\pi rj}{k}</span> $ for $ j = 1, 2, …, k $. Each sample point on the ring then has coordinates:</p>
<p>$ (x_j, y_j) = (x_:nbsphinx-math:<cite>theta `+ r cos⁡(:nbsphinx-math:</cite>theta`_j), y:nbsphinx-math:<cite>theta `+ r sin⁡(:nbsphinx-math:</cite>theta`_j)) $</p>
<p>where $ (x_:nbsphinx-math:<cite>theta</cite>, y_:nbsphinx-math:<cite>theta</cite>) (x_:nbsphinx-math:<cite>theta`​, y_:nbsphinx-math:</cite>theta`​) $ is the central point (the peak) and $ r $ is the radius of the ring.</p>
</li>
<li><p>Evaluating the KDE at Each Sample Point: For each point $ (x_j, y_j) $ on the ring, we evaluate the KDE surface to get a density estimate $ KDE(x_j, y_j) $.</p></li>
<li><p>Averaging the Densities: The density estimate for the ring at radius $ r $ is the average of the KDE values around the ring:</p>
<p>$ KDE_{rad}(r) = <span class="math">\frac{1}{k}</span> <span class="math">\sum</span>_{j=1}^k KDE(x_j, y_j) $</p>
<p>where $ k $ is the number of sample points along the ring. The more points we sample (i.e., the larger $ k $), the closer this estimate will be to the true density profile around the ring.</p>
</li>
<li><p>Constructing the Radial KDE Profile: By repeating this process for each radius $ r_i $ in our sequence $ { r_1, r_2, … , r_n } $, we construct a radial density profile. This profile is a smooth function of distance from the central peak, providing a continuous view of how density changes with distance.</p></li>
</ol>
<p>Radial KDE has another advantage when used with the chronocluster package: when applied to a KDE surface that has already been weighted by temporal probabilities (such as inclusion probabilities from time-sliced KDEs), it implicitly incorporates chronological uncertainty. This unified profile provides a more robust view of density trends as they would appear over time in archaeological research.</p>
</section>
</section>
<section id="Radial-KDE-in-chronocluster">
<h3>Radial KDE in chronocluster<a class="headerlink" href="#Radial-KDE-in-chronocluster" title="Link to this heading"></a></h3>
<p>With all of that in mind, there are functions in the chronocluster package for producing radial KDEs and radial densities. The two are <code class="docutils literal notranslate"><span class="pre">radial_density</span></code> and <code class="docutils literal notranslate"><span class="pre">radial_kde</span></code>. The latter is the primary tool that uses the chronocluster paradigm since it calls the previously described functions for producing a KDE given the characteristic scale(s) identified and the time slice in a STV for which the KDE profile is desired.</p>
<p>We can begin by simply calling <code class="docutils literal notranslate"><span class="pre">radial_kde</span></code> as follows, passing in one of the important peaks contained in <code class="docutils literal notranslate"><span class="pre">summary_df</span></code> that was identified with the <code class="docutils literal notranslate"><span class="pre">kde_peaks</span></code> method:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[49]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">chronocluster.density</span> <span class="kn">import</span> <span class="n">radial_kde</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">halfnorm</span>

<span class="c1"># Define parameters</span>
<span class="n">center</span> <span class="o">=</span> <span class="n">summary_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;Coordinates&#39;</span><span class="p">]</span>
<span class="n">radii</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>  <span class="c1"># Radii from 500 to 5000 meters</span>
<span class="n">point_density</span> <span class="o">=</span> <span class="mf">0.01</span>  <span class="c1"># 0.01 points per meter along each ring</span>
<span class="n">time_slice</span> <span class="o">=</span> <span class="n">time_slices</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mf">1.5</span>

<span class="c1"># Compute radial KDE profile</span>
<span class="n">radial_profile</span> <span class="o">=</span> <span class="n">radial_kde</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">time_slice</span><span class="p">,</span> <span class="n">bandwidth</span><span class="p">,</span> <span class="n">center</span><span class="p">,</span> <span class="n">radii</span><span class="p">,</span> <span class="n">point_density</span><span class="p">)</span>

<span class="c1"># Scale the radial profile to max = 1</span>
<span class="n">scaled_radial_profile</span> <span class="o">=</span> <span class="n">radial_profile</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">radial_profile</span><span class="p">)</span>

<span class="c1"># Compute and scale the half-normal density</span>
<span class="n">half_normal_density</span> <span class="o">=</span> <span class="n">halfnorm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">radii</span><span class="p">,</span> <span class="n">scale</span> <span class="o">=</span> <span class="n">target_scale</span><span class="p">)</span>
<span class="n">scaled_half_normal_density</span> <span class="o">=</span> <span class="n">half_normal_density</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">half_normal_density</span><span class="p">)</span>

<span class="c1"># Plot scaled radial profile and scaled half-normal density</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">radii</span><span class="p">,</span> <span class="n">scaled_radial_profile</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Radial Density (Scaled KDE)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">radii</span><span class="p">,</span> <span class="n">scaled_half_normal_density</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Half-Normal (Scaled)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Radius (meters)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Density (Scaled)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Radial Density Profile vs. Half-Normal Distribution&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="_images/tutorialnb_70_0.png" src="_images/tutorialnb_70_0.png" />
</div>
</div>
<p>As anticipated, the radial KDE looks like the profile of a half-normal density. This means that the radial KDE function is performing as expected and we have identified a valid peak in the density that corresponds to the simulated data parameters. The standard deviation also looks approximately correct, at around 1-1.5.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="tutorial.html" class="btn btn-neutral float-left" title="Tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="modules.html" class="btn btn-neutral float-right" title="Modules" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, W. Christopher Carleton.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>